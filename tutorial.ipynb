{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer 是一种革命性的深度学习模型架构，主要用于自然语言处理（NLP）任务。它由Google在2017年的论文《Attention is All You Need》中首次提出。以下是Transformer的核心特点：\n",
    "\n",
    "1. **自注意力机制（Self-Attention）**：\n",
    "   - 这是Transformer的核心创新\n",
    "   - 允许模型在处理每个词时关注输入序列中的所有词\n",
    "   - 能够捕捉长距离依赖关系\n",
    "\n",
    "2. **并行计算**：\n",
    "   - 与RNN不同，Transformer可以并行处理整个序列\n",
    "   - 大大提高了训练效率\n",
    "\n",
    "3. **编码器-解码器结构**：\n",
    "   - 编码器：将输入序列转换为一系列特征表示\n",
    "   - 解码器：根据编码器的输出生成目标序列\n",
    "\n",
    "4. **位置编码**：\n",
    "   - 由于Transformer没有循环结构，需要额外添加位置信息\n",
    "   - 通过正弦/余弦函数或学习得到的位置编码来实现\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer模型可以主要分为以下几个核心部分：\n",
    "\n",
    "1. **输入部分（Input Processing）**\n",
    "   - 词嵌入（Word Embedding）\n",
    "   - 位置编码（Positional Encoding）\n",
    "\n",
    "2. **编码器部分（Encoder）**\n",
    "   - 多头自注意力机制（Multi-Head Self-Attention）\n",
    "   - 前馈神经网络（Feed Forward Network）\n",
    "   - 残差连接和层归一化（Residual Connection & Layer Normalization）\n",
    "\n",
    "3. **解码器部分（Decoder）**\n",
    "   - 掩码多头自注意力机制（Masked Multi-Head Self-Attention）\n",
    "   - 编码器-解码器注意力机制（Encoder-Decoder Attention）\n",
    "   - 前馈神经网络（Feed Forward Network）\n",
    "   - 残差连接和层归一化（Residual Connection & Layer Normalization）\n",
    "\n",
    "4. **输出部分（Output）**\n",
    "   - 线性变换（Linear Transformation）\n",
    "   - Softmax层\n",
    "\n",
    "5. **辅助组件**\n",
    "   - 注意力机制（Attention Mechanism）\n",
    "   - 位置前馈网络（Position-wise Feed Forward Network）\n",
    "   - 残差连接（Residual Connections）\n",
    "   - 层归一化（Layer Normalization）\n",
    "\n",
    "每个部分的具体作用：\n",
    "- **输入部分**：将离散的单词转换为连续的向量表示，并加入位置信息\n",
    "- **编码器**：提取输入序列的特征表示\n",
    "- **解码器**：根据编码器的输出和已生成的部分序列，预测下一个单词\n",
    "- **输出部分**：将解码器的输出转换为概率分布，用于预测下一个单词\n",
    "- **辅助组件**：帮助模型更好地训练和收敛\n",
    "\n",
    "这些部分共同构成了Transformer模型，使其能够有效地处理序列数据，并在各种NLP任务中取得优异的表现。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Input Processing 🐱 输入处理\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.1 词嵌入（Word Embedding）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 1. **什么是nn.Embedding？**\n",
    "`nn.Embedding`是PyTorch中的一个模块，用于将离散的整数索引（通常是单词的索引）转换为连续的向量表示。它本质上是一个查找表，其中每个索引对应一个固定大小的向量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### 2. **主要参数：**\n",
    "- `num_embeddings`：词汇表的大小，即有多少个不同的单词\n",
    "- `embedding_dim`：每个单词向量的维度\n",
    "- `padding_idx`（可选）：用于指定填充符号的索引，该索引对应的向量不会更新\n",
    "- `max_norm`（可选）：如果指定，会对向量进行归一化\n",
    "- `norm_type`（可选）：归一化的类型，默认是L2范数\n",
    "- `scale_grad_by_freq`（可选）：是否根据词频缩放梯度\n",
    "- `sparse`（可选）：是否使用稀疏梯度更新\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 3. **独立使用示例：**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入索引： tensor([2, 5, 1])\n",
      "输出向量：\n",
      " tensor([[ 0.7635, -0.3061,  1.9398],\n",
      "        [ 0.1489, -0.5646,  1.9929],\n",
      "        [-1.0705, -0.8970, -1.6495]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设我们有一个词汇表，包含10个单词\n",
    "vocab_size = 10\n",
    "# 每个单词用3维向量表示\n",
    "embedding_dim = 3\n",
    "\n",
    "# 创建Embedding层\n",
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "# 输入是一个包含单词索引的张量\n",
    "# 例如：[2, 5, 1] 表示一个包含3个单词的句子\n",
    "input_indices = torch.tensor([2, 5, 1])\n",
    "\n",
    "# 通过Embedding层获取对应的词向量\n",
    "output_vectors = embedding(input_indices)\n",
    "\n",
    "print(\"输入索引：\", input_indices)\n",
    "print(\"输出向量：\\n\", output_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 4. **输出的解释**\n",
    "\n",
    "- 每个单词索引（如2, 5, 1）被转换为一个3维向量\n",
    "- 这些向量是随机初始化的，可以在训练过程中学习\n",
    "- `grad_fn`表示这些向量是可训练的，会随着模型训练而更新\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### 5. **实际应用场景：**\n",
    "- 自然语言处理（NLP）中，用于将单词转换为向量\n",
    "- 推荐系统中，用于将用户ID或物品ID转换为向量\n",
    "- 任何需要将离散索引映射到连续向量的场景\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.2 位置编码 🐱 Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 1. **什么是位置编码？**\n",
    "位置编码（Positional Encoding）是Transformer模型中用于为输入序列添加位置信息的一种方法。由于Transformer没有像RNN那样的循环结构，它需要额外的机制来理解单词在序列中的位置。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 2. **为什么需要位置编码？**\n",
    "- **Transformer的局限性**：Transformer使用自注意力机制，可以并行处理整个序列，但无法直接获取序列中元素的位置信息\n",
    "- **保持顺序信息**：自然语言中，单词的顺序非常重要，位置编码帮助模型理解这种顺序\n",
    "- **捕捉相对位置**：位置编码的设计使得模型能够捕捉到元素之间的相对位置关系\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **位置编码的公式：**\n",
    "位置编码使用正弦和余弦函数的组合：\n",
    "```\n",
    "PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "```\n",
    "其中：\n",
    "- `pos`：单词在序列中的位置\n",
    "- `i`：维度索引\n",
    "- `d_model`：模型的维度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### 4. **位置编码的特点：**\n",
    "- **周期性**：使用正弦和余弦函数，使得编码具有周期性\n",
    "- **可学习性**：虽然位置编码是固定的，但模型可以通过学习来利用这些信息\n",
    "- **相对位置**：不同位置之间的编码关系可以帮助模型理解相对位置\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. **独立使用示例：**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始词向量形状： torch.Size([2, 10, 16])\n",
      "位置编码形状： torch.Size([1, 100, 16])\n",
      "添加位置编码后的形状： torch.Size([2, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class PositionalEncoding:\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.pe = self._generate_position_encoding()\n",
    "        \n",
    "    def _generate_position_encoding(self):\n",
    "        position = torch.arange(self.max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.d_model, 2) * \n",
    "                           -(math.log(10000.0) / self.d_model))\n",
    "        pe = torch.zeros(self.max_len, self.d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # x: (batch_size, seq_len, d_model)\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len, :]\n",
    "\n",
    "# 模型的维度，即每个词向量的长度\n",
    "# 这个值决定了位置编码和词嵌入的维度\n",
    "# 通常选择2的幂次方（如16, 32, 64, 128, 256, 512等）\n",
    "# 较大的维度可以捕捉更丰富的信息，但会增加计算量\n",
    "d_model = 16\n",
    "\n",
    "# 最大序列长度，即位置编码支持的最长序列\n",
    "# 这个值应该大于或等于实际输入序列的最大长度\n",
    "# 如果输入序列超过这个长度，位置编码将无法正确表示\n",
    "# 通常设置为一个足够大的值（如100, 200, 512, 1024等）\n",
    "max_len = 100\n",
    "\n",
    "# 批量大小，即一次处理的样本数量\n",
    "# 较大的批量大小可以提高训练效率，但需要更多内存\n",
    "# 通常根据GPU内存大小和模型复杂度来选择\n",
    "batch_size = 2\n",
    "\n",
    "# 序列长度，即每个样本的单词数量\n",
    "# 这个值应该小于或等于max_len\n",
    "# 如果序列长度不同，通常需要进行填充或截断\n",
    "# 在实际应用中，这个值会根据具体任务而变化\n",
    "seq_len = 10\n",
    "\n",
    "# 假设我们有一些随机生成的词向量\n",
    "word_embeddings = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "# 创建位置编码器\n",
    "pos_encoder = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "# 添加位置编码\n",
    "output = pos_encoder(word_embeddings)\n",
    "\n",
    "print(\"原始词向量形状：\", word_embeddings.shape)\n",
    "print(\"位置编码形状：\", pos_encoder.pe.shape)\n",
    "print(\"添加位置编码后的形状：\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. **输出解释：**\n",
    "\n",
    "```python\n",
    "原始词向量形状： torch.Size([2, 10, 16])\n",
    "位置编码形状： torch.Size([1, 100, 16])\n",
    "添加位置编码后的形状： torch.Size([2, 10, 16])\n",
    "```\n",
    "\n",
    "这些输出形状反映了Transformer模型中输入处理的不同阶段：\n",
    "\n",
    "1. **原始词向量形状：torch.Size([2, 10, 16])**\n",
    "   - `2`：批量大小（batch_size），表示同时处理2个样本\n",
    "   - `10`：序列长度（seq_len），表示每个样本包含10个单词\n",
    "   - `16`：模型维度（d_model），表示每个单词用16维向量表示\n",
    "\n",
    "2. **位置编码形状：torch.Size([1, 100, 16])**\n",
    "   - `1`：表示位置编码是固定的，对所有样本都相同\n",
    "   - `100`：最大序列长度（max_len），表示位置编码支持的最长序列\n",
    "   - `16`：模型维度（d_model），与词向量维度一致，方便相加\n",
    "\n",
    "3. **添加位置编码后的形状：torch.Size([2, 10, 16])**\n",
    "   - `2`：批量大小保持不变\n",
    "   - `10`：序列长度保持不变\n",
    "   - `16`：模型维度保持不变\n",
    "\n",
    "**维度一致性的原因：**\n",
    "- 位置编码的维度`[1, 100, 16]`中，`1`表示位置编码是共享的，`100`是预先生成的最大长度，`16`与词向量维度一致\n",
    "- 在实际使用时，我们只取前`seq_len`个位置编码（`pos_encoder.pe[:, :seq_len, :]`），因此可以与词向量`[2, 10, 16]`直接相加\n",
    "- 相加操作利用了PyTorch的广播机制，将`[1, 10, 16]`的位置编码广播到`[2, 10, 16]`，与词向量逐元素相加\n",
    "\n",
    "这种设计确保了：\n",
    "1. 位置信息能够正确地添加到每个单词的向量表示中\n",
    "2. 不同样本可以共享相同的位置编码，提高效率\n",
    "3. 模型能够处理不同长度的序列，只要不超过最大长度`max_len`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "现在让我们把刚刚提到的`Embedding`和`PositionalEncoding`组合成一个完整的预处理模块`TransformerPreprocessor`。你可以在`transformer_preprocess.py`中找到一样的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class TransformerPreprocessor(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, max_seq_len):\n",
    "        super(TransformerPreprocessor, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_encoding = PositionalEncoding(d_model, max_seq_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len)\n",
    "        embeddings = self.embedding(x)  # (batch_size, seq_len, d_model)\n",
    "        output = self.position_encoding(embeddings)  # (batch_size, seq_len, d_model)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding:\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.pe = self._generate_position_encoding()\n",
    "        \n",
    "    def _generate_position_encoding(self):\n",
    "        position = torch.arange(self.max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.d_model, 2) * \n",
    "                           -(math.log(10000.0) / self.d_model))\n",
    "        pe = torch.zeros(self.max_len, self.d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # x: (batch_size, seq_len, d_model)\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len, :]\n",
    "\n",
    "# 使用示例\n",
    "vocab_size = 10000\n",
    "d_model = 512\n",
    "max_seq_len = 100\n",
    "batch_size = 32\n",
    "seq_len = 50\n",
    "\n",
    "preprocessor = TransformerPreprocessor(vocab_size, d_model, max_seq_len)\n",
    "input_ids = torch.randint(0, vocab_size, (batch_size, seq_len))  # 随机生成输入\n",
    "output = preprocessor(input_ids)\n",
    "print(output.shape)  # 输出: torch.Size([32, 50, 512])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Encoder 🐱 编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.1 Multi-Head Attention 🐱 多头注意力机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "多头注意力机制通过并行计算多个注意力头，捕捉输入序列中不同子空间的特征。每个注意力头独立计算注意力分数，然后将结果拼接起来，最后通过线性变换得到输出。\n",
    "\n",
    "多头注意力机制可以分为以下几个关键步骤：\n",
    "1. 线性变换：将输入映射为查询（Q）、键（K）、值（V）。\n",
    "2. 分割多头：将Q、K、V拆分为多个注意力头。\n",
    "3. 计算注意力分数：计算Q和K的点积，并进行缩放和softmax。\n",
    "4. 加权求和：使用注意力权重对V进行加权求和。\n",
    "5. 拼接多头：将多个注意力头的输出拼接回原始维度。\n",
    "6. 线性变换：对拼接后的结果进行线性变换。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **2.1.1 线性变换 Q K V**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "在多头注意力机制中，**线性变换**是将输入特征映射为查询（Q）、键（K）、值（V）的关键步骤。以下是详细解释：\n",
    "\n",
    "---\n",
    "\n",
    "##### 1. **线性变换的定义**\n",
    "线性变换是通过矩阵乘法将输入特征**映射到新的特征空间**。具体来说：\n",
    "- 输入：`x`，形状为`(batch_size, seq_len, d_model)`。\n",
    "- 输出：`Q`、`K`、`V`，形状仍为`(batch_size, seq_len, d_model)`，但特征表示已经不同。\n",
    "\n",
    "数学公式：\n",
    "```python\n",
    "Q = x · W_Q\n",
    "K = x · W_K\n",
    "V = x · W_V\n",
    "```\n",
    "其中：\n",
    "- `W_Q`、`W_K`、`W_V`是可学习的权重矩阵，形状为`(d_model, d_model)`。我认为在这里，以实用的角度来讲，不必深究`Q`、`K`、`V`的意义，只需要知道它们是通过线性变换得到的即可。`x`的形状是什么，那么`Q`、`K`、`V`的形状就是什么，只不过这些矩阵将他们分别映射到了不同的特征空间。\n",
    "- `·`表示矩阵乘法。\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. **线性变换的作用**\n",
    "- **特征空间的转换**：\n",
    "  - 原有的输入特征`x`可能是词嵌入或位置编码后的表示，这些特征不一定适合直接用于计算注意力分数。\n",
    "  - 通过线性变换，将`x`映射到更适合计算注意力的特征空间。\n",
    "- **增加模型的表达能力**：\n",
    "  - 线性变换引入了可学习的参数，使模型能够根据任务需求动态调整Q、K、V的表示。\n",
    "  - 这样，模型可以捕捉输入序列中更复杂的依赖关系。\n",
    "- **分离不同的角色**：\n",
    "  - Q、K、V在注意力机制中扮演不同的角色：\n",
    "    - **Q（Query）**：表示当前需要关注的位置。\n",
    "    - **K（Key）**：表示其他位置的特征，用于与Q计算相似度。\n",
    "    - **V（Value）**：表示其他位置的实际信息，用于加权求和。\n",
    "  - 通过独立的线性变换，Q、K、V可以学习到不同的特征表示。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👇在这里，我们使用提到的`TransformermerPreprocessor`来对输入进行预处理，获取一个`x`以便给我们接下来的*线性变换*做示范。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入 x 的形状： torch.Size([32, 50, 512])\n"
     ]
    }
   ],
   "source": [
    "from transformer_preprocess import TransformerPreprocessor\n",
    "\n",
    "vocab_size = 10000\n",
    "d_model = 512\n",
    "max_seq_len = 100\n",
    "batch_size = 32\n",
    "seq_len = 50\n",
    "\n",
    "preprocessor = TransformerPreprocessor(vocab_size, d_model, max_seq_len)\n",
    "input_ids = torch.randint(0, vocab_size, (batch_size, seq_len))  # 随机生成输入\n",
    "x = preprocessor(input_ids)\n",
    "# print(\"输入 x:\\n\", x)\n",
    "print(\"输入 x 的形状：\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "我们定义三个线性变换层，分别用于生成Q、K、V，这三个东西（`query`, `key`, `value`）就是我们刚刚提到的三个权重矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "query = nn.Linear(d_model, d_model)  # 查询变换\n",
    "key = nn.Linear(d_model, d_model)    # 键变换\n",
    "value = nn.Linear(d_model, d_model)  # 值变换\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "通过线性变换将输入`x`映射为Q、K、V："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\n",
      " tensor([[[ 5.1458e-01,  2.2833e+00,  3.4339e-01,  ...,  3.1720e-01,\n",
      "           5.5931e-01, -2.4716e-01],\n",
      "         [ 2.1290e-01,  1.4330e+00,  3.3144e-02,  ..., -1.0922e-01,\n",
      "           1.2623e+00,  4.3433e-01],\n",
      "         [-1.1843e+00,  1.0601e+00,  2.2368e-01,  ...,  2.0080e-01,\n",
      "           1.1263e+00, -3.9656e-02],\n",
      "         ...,\n",
      "         [ 7.6759e-01, -7.7738e-01,  8.9393e-02,  ..., -4.7689e-01,\n",
      "           3.0393e-01, -5.3094e-01],\n",
      "         [ 2.4509e-01,  6.8523e-01, -5.5103e-01,  ...,  6.9781e-01,\n",
      "          -1.9352e-01, -1.7317e-01],\n",
      "         [ 1.0272e+00, -4.5884e-01, -1.7615e-01,  ..., -1.1869e-01,\n",
      "          -1.3729e-01, -1.1081e-01]],\n",
      "\n",
      "        [[ 5.8952e-01,  8.8362e-01, -5.2984e-02,  ...,  2.7867e-01,\n",
      "          -4.8920e-01,  4.8502e-02],\n",
      "         [ 2.2018e-01,  6.5371e-01,  6.2374e-01,  ..., -1.2333e+00,\n",
      "          -1.8203e-01, -2.5497e-01],\n",
      "         [ 1.4411e+00, -3.8728e-01, -1.7061e-01,  ...,  4.7457e-01,\n",
      "          -5.5097e-01, -4.3525e-01],\n",
      "         ...,\n",
      "         [ 1.3209e+00,  1.4224e-01,  7.3435e-01,  ...,  8.3999e-02,\n",
      "          -3.7927e-01, -1.2146e+00],\n",
      "         [ 1.8057e-01,  1.4087e-01, -6.1568e-01,  ...,  5.2938e-01,\n",
      "          -7.1534e-01, -5.8486e-01],\n",
      "         [ 2.8142e-01, -2.5178e-01, -9.7559e-01,  ...,  1.1904e+00,\n",
      "          -6.1171e-01, -3.8804e-01]],\n",
      "\n",
      "        [[ 7.7218e-02, -2.7046e-01,  1.6272e+00,  ..., -2.4043e-02,\n",
      "          -2.7102e-01, -5.6758e-03],\n",
      "         [-6.8536e-01,  8.8756e-01,  9.1941e-01,  ...,  1.9300e-01,\n",
      "           1.2814e+00, -3.8445e-01],\n",
      "         [-2.3585e-01,  1.1706e+00, -5.7548e-01,  ..., -4.1204e-02,\n",
      "          -5.3989e-01, -1.1810e+00],\n",
      "         ...,\n",
      "         [ 6.3281e-02,  1.1587e-01, -2.8790e-01,  ..., -2.4262e-01,\n",
      "           1.7565e-01,  8.1798e-01],\n",
      "         [ 7.6219e-01, -1.3254e+00, -4.3132e-01,  ..., -2.5967e-01,\n",
      "           3.4332e-01, -8.7450e-02],\n",
      "         [ 5.1346e-01,  9.0260e-01,  6.3747e-02,  ..., -4.6030e-01,\n",
      "          -9.6718e-02,  3.6015e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.9795e-01,  9.6634e-01, -5.5415e-02,  ...,  9.5592e-01,\n",
      "           5.2844e-01, -4.2077e-01],\n",
      "         [ 9.0152e-01,  1.0490e+00,  6.3685e-01,  ...,  6.8426e-01,\n",
      "           3.4906e-01, -1.1649e+00],\n",
      "         [-2.8851e-02,  2.4549e-01,  9.0390e-01,  ...,  2.0921e-02,\n",
      "           4.9698e-01, -9.4199e-01],\n",
      "         ...,\n",
      "         [ 6.2351e-01,  5.0576e-01, -6.0008e-02,  ...,  7.3410e-01,\n",
      "           6.7453e-02, -2.9301e-01],\n",
      "         [ 4.1429e-01,  5.9322e-01,  6.1523e-01,  ...,  6.9272e-01,\n",
      "          -5.6743e-01,  1.0031e-01],\n",
      "         [ 6.7432e-01,  1.6077e+00, -5.2298e-02,  ..., -4.3212e-02,\n",
      "          -6.5740e-01, -7.7098e-01]],\n",
      "\n",
      "        [[ 1.0566e-01, -1.5259e-01, -9.2431e-01,  ..., -4.9602e-01,\n",
      "          -2.2778e-01, -4.2410e-02],\n",
      "         [-3.4924e-01,  2.7278e-01,  1.6128e+00,  ..., -6.2379e-01,\n",
      "           6.7378e-01, -5.6269e-01],\n",
      "         [-7.4991e-01, -1.3912e-01,  4.2950e-01,  ..., -5.7577e-01,\n",
      "           2.3001e-01, -6.0930e-01],\n",
      "         ...,\n",
      "         [ 5.5717e-01,  6.6279e-01, -2.4108e-01,  ...,  1.7320e-03,\n",
      "           1.2246e-01, -6.8348e-01],\n",
      "         [ 7.4861e-01,  1.0803e+00, -4.2307e-01,  ..., -1.6015e-01,\n",
      "           3.7570e-01, -5.6848e-01],\n",
      "         [ 1.2640e-01, -2.3703e-01,  4.6268e-02,  ...,  5.5842e-01,\n",
      "          -5.3538e-01,  6.8779e-01]],\n",
      "\n",
      "        [[-2.6247e-01,  1.5201e-01,  2.3512e-01,  ..., -4.1332e-01,\n",
      "           1.7054e+00,  2.1192e-01],\n",
      "         [-1.7251e-01,  1.1070e+00,  3.9869e-01,  ...,  2.2703e-01,\n",
      "          -9.8373e-01, -7.6707e-01],\n",
      "         [-7.1836e-02,  3.0061e-01, -1.0803e-01,  ...,  4.7453e-01,\n",
      "          -1.2184e-01,  1.5057e-01],\n",
      "         ...,\n",
      "         [ 6.2122e-01,  6.8317e-01, -8.3573e-01,  ...,  4.4307e-02,\n",
      "          -1.3450e-01, -7.9532e-01],\n",
      "         [ 1.6173e+00,  1.4077e+00, -5.3676e-01,  ...,  9.1648e-01,\n",
      "          -1.4724e-01,  1.3350e-01],\n",
      "         [ 1.5731e-01,  6.3291e-01, -3.0655e-01,  ...,  9.2024e-01,\n",
      "           1.8289e-01, -1.3861e+00]]], grad_fn=<ViewBackward0>)\n",
      "Q 的形状： torch.Size([32, 50, 512])\n",
      "\n",
      "\n",
      "K:\n",
      " tensor([[[ 0.4707,  0.0985, -0.5763,  ..., -0.3135,  0.6340,  0.2160],\n",
      "         [-0.4512,  0.7647, -0.9731,  ..., -0.2167,  1.7220,  0.0908],\n",
      "         [ 0.3059, -0.0522, -0.0956,  ..., -0.3413,  0.8344,  0.9463],\n",
      "         ...,\n",
      "         [ 0.3839,  0.5351,  0.7636,  ...,  0.4332,  1.5855,  0.8775],\n",
      "         [-0.3332, -1.7537,  0.0633,  ...,  0.2778,  1.6513, -0.2663],\n",
      "         [ 0.1704, -0.8277, -0.2329,  ...,  0.2181,  0.6032,  1.0581]],\n",
      "\n",
      "        [[ 1.5271, -0.1429, -1.2526,  ...,  0.4460, -0.4482,  0.7242],\n",
      "         [ 1.0337, -0.5462, -0.2113,  ..., -0.0707,  1.0927,  0.3666],\n",
      "         [ 0.5459, -0.8304, -0.5947,  ...,  0.2200,  1.5324,  0.6365],\n",
      "         ...,\n",
      "         [ 0.0527,  0.0468, -0.3509,  ..., -0.4482,  1.9739,  0.9973],\n",
      "         [-0.2595,  1.2760,  0.4441,  ...,  0.1264, -0.2509,  1.0306],\n",
      "         [ 0.7819, -0.5834,  0.4613,  ...,  0.5233,  1.4134,  0.6525]],\n",
      "\n",
      "        [[ 1.0538,  0.7070, -0.1435,  ..., -0.2184,  1.2290,  0.6454],\n",
      "         [ 0.6485,  0.3412, -1.8089,  ...,  0.2463,  1.5279,  0.3438],\n",
      "         [ 0.8581,  0.3941, -0.6920,  ..., -0.2491,  0.6091,  0.1043],\n",
      "         ...,\n",
      "         [-0.8889,  0.4279, -0.9599,  ..., -0.3975, -0.1120,  1.3142],\n",
      "         [-0.1479, -0.6575, -0.4335,  ..., -0.3357,  0.6659,  0.8381],\n",
      "         [ 0.3399, -0.3412, -0.5181,  ...,  0.5648,  0.6946,  2.0284]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6199,  0.9375, -1.0017,  ..., -1.4418,  0.9067,  1.3128],\n",
      "         [ 1.8888, -0.2028,  0.9671,  ...,  0.1002,  2.1149, -0.0652],\n",
      "         [ 0.6178, -0.4442,  0.9255,  ...,  0.1661,  1.4212,  1.1540],\n",
      "         ...,\n",
      "         [ 0.2884, -0.2827, -0.3380,  ...,  0.1989,  0.9632,  2.3930],\n",
      "         [ 0.7821, -1.1350, -0.9928,  ...,  0.0927,  0.6912,  0.4539],\n",
      "         [ 0.9110, -1.0679, -1.1115,  ...,  0.7594,  0.5265,  1.1347]],\n",
      "\n",
      "        [[ 0.3743,  1.1453,  0.6232,  ..., -0.3962,  0.3440,  1.1971],\n",
      "         [ 2.1493,  0.7704, -0.2869,  ..., -0.2910,  2.3130,  0.2276],\n",
      "         [ 0.5086, -0.0742, -0.2352,  ..., -0.7143,  0.8120, -0.2077],\n",
      "         ...,\n",
      "         [-0.4815,  0.3604,  0.1381,  ...,  0.1396,  2.4726,  0.1204],\n",
      "         [-0.4165,  0.3099, -0.3325,  ...,  0.5994, -0.0802,  1.4197],\n",
      "         [-0.3682, -0.1010,  0.0052,  ..., -0.0991,  1.1545,  0.8153]],\n",
      "\n",
      "        [[ 0.7336,  0.0570, -0.5292,  ..., -0.5181,  1.1433,  0.0455],\n",
      "         [ 0.3399,  0.3215, -0.2899,  ..., -0.4347,  1.1704,  0.7677],\n",
      "         [-0.3643,  1.4756, -0.7735,  ..., -0.2469,  0.4160,  0.3308],\n",
      "         ...,\n",
      "         [-0.4472,  0.7008,  0.4595,  ..., -0.9850,  0.5498,  0.0521],\n",
      "         [ 0.1599,  0.3365,  0.2441,  ..., -0.4765,  0.7921, -0.0972],\n",
      "         [-0.5657, -0.2071, -0.3352,  ...,  0.6912,  0.6643,  0.9809]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "K 的形状： torch.Size([32, 50, 512])\n",
      "\n",
      "\n",
      "V:\n",
      " tensor([[[-0.3062,  0.3950, -0.6900,  ...,  1.0096, -0.6683, -0.3471],\n",
      "         [-0.3913,  0.6261, -0.0176,  ...,  1.5289, -0.4983, -0.5231],\n",
      "         [-0.0854, -0.4787,  0.7792,  ...,  0.1428, -0.3427,  0.2189],\n",
      "         ...,\n",
      "         [ 0.4108,  0.2689, -0.3190,  ...,  1.4354, -0.9665, -0.1730],\n",
      "         [-0.8781, -0.0713,  1.2062,  ...,  1.7957, -0.3921, -1.1995],\n",
      "         [ 0.7048, -0.0133, -0.0126,  ...,  1.4032, -0.0048, -0.4373]],\n",
      "\n",
      "        [[-0.0585, -0.5212, -0.3861,  ...,  0.5690, -0.8816, -0.9672],\n",
      "         [ 0.7798, -0.1663, -0.2288,  ...,  0.8773, -0.8172, -0.7123],\n",
      "         [ 0.1188,  0.6061,  0.0767,  ...,  0.5896, -0.3588, -0.6541],\n",
      "         ...,\n",
      "         [-0.1751, -0.3647, -1.3535,  ...,  0.7074, -1.3883,  0.2526],\n",
      "         [-0.3618, -0.3058,  0.3589,  ...,  1.6831, -0.4348,  0.2876],\n",
      "         [-0.6029,  0.3035, -0.2157,  ...,  1.1197, -0.9348,  0.4754]],\n",
      "\n",
      "        [[ 0.6124,  0.3480,  0.1952,  ...,  1.0696, -1.2496,  0.7406],\n",
      "         [-0.1207,  0.5282, -0.2220,  ...,  1.0321,  0.0880, -0.0163],\n",
      "         [ 1.2860,  0.8477, -0.8822,  ...,  0.7443, -0.7386, -0.3389],\n",
      "         ...,\n",
      "         [-0.3080, -0.2699, -0.1580,  ...,  1.6660, -0.8911, -0.3837],\n",
      "         [-0.4384,  0.4441, -0.0490,  ...,  1.0788, -0.3407,  0.2178],\n",
      "         [-1.3192, -0.1289, -0.5313,  ...,  0.3477, -0.9029,  0.5291]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2922, -0.1877, -1.1507,  ...,  0.6252, -0.4443, -2.0985],\n",
      "         [ 0.9129,  0.4660,  0.5545,  ...,  0.5358,  0.5943, -0.8418],\n",
      "         [ 0.9533, -0.0090, -0.1832,  ...,  1.1225,  0.7060, -0.0749],\n",
      "         ...,\n",
      "         [-1.0294,  0.9765, -0.5629,  ...,  1.2564, -0.5926,  0.5211],\n",
      "         [-1.2155,  0.6817, -0.7749,  ..., -0.2976,  0.2625, -0.3755],\n",
      "         [ 0.0091, -0.0260,  1.2980,  ..., -0.0853,  0.1067,  1.1689]],\n",
      "\n",
      "        [[-1.4527,  0.7902, -0.3831,  ...,  1.9439, -1.0708,  0.0472],\n",
      "         [ 0.2366, -0.5390,  0.4590,  ...,  1.5362, -0.6225, -0.4159],\n",
      "         [ 0.5433,  1.2487,  0.3427,  ...,  1.1441,  0.4942,  0.5435],\n",
      "         ...,\n",
      "         [-0.0724,  0.2417, -0.2754,  ...,  1.1475,  0.0149, -0.0875],\n",
      "         [ 0.3865,  0.5091, -0.1349,  ...,  1.4119, -0.1076,  0.4481],\n",
      "         [-0.4802, -0.4962, -0.0701,  ..., -0.5609, -0.6538, -0.2138]],\n",
      "\n",
      "        [[-1.6495,  0.2277, -0.7972,  ..., -0.2461, -0.4957, -0.6568],\n",
      "         [ 1.7536, -0.1615, -0.6663,  ...,  0.6973, -0.4325,  0.2436],\n",
      "         [-1.2347,  0.2066,  0.2151,  ...,  0.6433,  0.3169,  0.9544],\n",
      "         ...,\n",
      "         [-0.7278,  0.0503, -0.6970,  ...,  0.7038, -0.4690,  0.6753],\n",
      "         [-0.6581,  0.2886,  0.2014,  ...,  0.3681,  0.3656,  0.3633],\n",
      "         [-0.5904,  1.1238,  0.2491,  ...,  0.2258, -0.5534,  0.7634]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "V 的形状： torch.Size([32, 50, 512])\n"
     ]
    }
   ],
   "source": [
    "Q = query(x)  # (batch_size, seq_len, d_model)\n",
    "K = key(x)    # (batch_size, seq_len, d_model)\n",
    "V = value(x)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "print(\"Q:\\n\", Q)\n",
    "print(\"Q 的形状：\", Q.shape)\n",
    "print(\"\\n\")\n",
    "print(\"K:\\n\", K)\n",
    "print(\"K 的形状：\", K.shape)\n",
    "print(\"\\n\")\n",
    "print(\"V:\\n\", V)\n",
    "print(\"V 的形状：\", V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 2.1.2 分割多头 🐱 将 Q K V 分割为多个注意力头\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### 1. **分割多头的目的**\n",
    "通过观察我们知道，刚刚得到的`Q/K/V`都是形如`torch.Size([32, 50, 512])`的矩阵。我们当然可以直接将它们作为输入，但这样做会导致模型关注相同的特征，而无法捕捉不同特征。Personally，我认为Attention原论文作者不想这么做的原因是：\n",
    "- **并行计算**：通过将Q、K、V拆分为多个注意力头，可以并行计算多个注意力分数，提高计算效率。这是transformer称霸NLP界的一个重要原因，它能高效利用GPU计算。\n",
    "- **捕捉不同特征**：每个注意力头可以关注输入序列中的不同子空间，捕捉更丰富的特征。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### 2. **分割多头的实现**\n",
    "假设：\n",
    "- `d_model`：模型维度（例如512，如之前所示）。\n",
    "- `num_heads`：注意力头的数量（例如16）。\n",
    "- `head_dim`：每个注意力头的维度（`d_model // num_heads`，例如512 // 16 = 32）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50, 512])\n"
     ]
    }
   ],
   "source": [
    "# Q, K, V 已经通过线性变换生成，我们在这里确认一下。\n",
    "batch_size, seq_len, d_model = Q.shape\n",
    "print(Q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这段代码中，`transpose(1, 2)`的作用是交换张量的第二个和第三个维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 的形状： torch.Size([32, 16, 50, 32])\n",
      "\n",
      "\n",
      "K 的形状： torch.Size([32, 16, 50, 32])\n",
      "\n",
      "\n",
      "V 的形状： torch.Size([32, 16, 50, 32])\n"
     ]
    }
   ],
   "source": [
    "num_heads = 16\n",
    "head_dim = d_model // num_heads\n",
    "\n",
    "# 分割多头：将 d_model 维度拆分为 num_heads * head_dim。在这我使用view方法对张量进行调整。\n",
    "# view之后，我们得到一个形状为(batch_size, seq_len, num_heads, head_dim)的张量。也就是torch.Size([32, 50, 16, 32])\n",
    "# 使用transpose将`num_heads`维度提到前面，方便后续并行计算，这时形状为(batch_size, num_heads, seq_len, head_dim)，也就是torch.Size([32, 16, 50, 32])。\n",
    "Q = Q.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "K = K.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "V = V.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "print(\"Q 的形状：\", Q.shape)\n",
    "print(\"\\n\")\n",
    "print(\"K 的形状：\", K.shape)\n",
    "print(\"\\n\")\n",
    "print(\"V 的形状：\", V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. **代码解释**\n",
    "1. **`view`操作**：\n",
    "   - 将`d_model`维度拆分为`num_heads * head_dim`。\n",
    "   - 例如，如果`d_model=５１２`，`num_heads=１６`，则`head_dim=３２`。\n",
    "   - 结果形状为`(batch_size, seq_len, num_heads, head_dim)`。\n",
    "\n",
    "2. **`transpose`操作**：\n",
    "   - 将`num_heads`维度提到前面，方便后续并行计算。\n",
    "   - 结果形状为`(batch_size, num_heads, seq_len, head_dim)`。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 2.1.3 计算注意力分数 🐱 Q 与 K 的点积\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. **计算注意力分数（点积）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "注意力分数 scores 的形状： torch.Size([32, 16, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "# 使用matmul而非dot是因为dot只适用一维向量\n",
    "scores = torch.matmul(Q, K.transpose(-2, -1))  # (batch_size, num_heads, seq_len, seq_len)\n",
    "print(\"注意力分数 scores 的形状：\", scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **解释**：\n",
    "  - 计算Q和K的点积，得到注意力分数。\n",
    "  - `Q`的形状为`(batch_size, num_heads, seq_len, head_dim)`。\n",
    "  - `K`的形状为`(batch_size, num_heads, seq_len, head_dim)`。\n",
    "  - `K.transpose(-2, -1)`将K的最后两个维度转置，形状变为`(batch_size, num_heads, head_dim, seq_len)`。\n",
    "  - 点积结果`score`的形状为`(batch_size, num_heads, seq_len, seq_len)`。\n",
    "\n",
    "通过转置K，我们使得Q的每一行可以与K的每一列进行点积，从而计算出每个位置与其他所有位置的相关性得分。这正是自注意力机制所需要的。\n",
    "\n",
    "如果你有一些线代的基础，其实不难理解得到的`score`的形状为`(batch_size, num_heads, seq_len, seq_len)`的原因：\n",
    "\n",
    "- 假设Q的形状为`(batch_size, num_heads, seq_len, head_dim)`，K的形状为`(batch_size, num_heads, seq_len, head_dim)`。\n",
    "- 通过`K.transpose(-2, -1)`，K的形状变为`(batch_size, num_heads, head_dim, seq_len)`。\n",
    "- 于是得到的矩阵形状就是`(batch_size, num_heads, seq_len, seq_len)`。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### **2. 缩放**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缩放后的注意力分数 scores 的形状： torch.Size([32, 16, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "scores = scores / torch.sqrt(torch.tensor(head_dim, dtype=torch.float32))\n",
    "print(\"缩放后的注意力分数 scores 的形状：\", scores.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **解释**：\n",
    "  - 使用`sqrt(head_dim)`对点积结果进行缩放。\n",
    "  - 这是为了防止点积结果过大，导致softmax的梯度消失。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为啥要用sqrt(head_dim)？**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 50, 128]) torch.Size([32, 16, 50, 128])\n",
      "torch.Size([32, 16, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设输入维度d_model较大\n",
    "d_model = 2048\n",
    "seq_len = 50\n",
    "batch_size = 32\n",
    "num_heads = 16\n",
    "head_dim = d_model // num_heads # 128\n",
    "\n",
    "# 随机生成 Q 和 K\n",
    "Q = torch.randn(batch_size, num_heads, seq_len, head_dim)  # (32, 8, 50, 128)\n",
    "K = torch.randn(batch_size, num_heads, seq_len, head_dim)  # (32, 8, 50, 128)\n",
    "print(Q.shape, K.shape)\n",
    "\n",
    "# 计算注意力分数（未缩放）\n",
    "scores = torch.matmul(Q, K.transpose(-2, -1))  # (32, 8, 50, 50)\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未缩放的注意力分数（部分）：\n",
      " tensor([[  2.4454,  -1.5969,   2.9058,  ...,  23.7999,  15.0058,  -5.0375],\n",
      "        [-16.2765,   0.4546,  24.8252,  ...,   4.0188,   5.7331,   0.7508],\n",
      "        [-16.1216,  -0.4666,  30.3811,  ...,   3.0736, -12.2189,   0.5960],\n",
      "        ...,\n",
      "        [  9.6764,   7.2761,  11.6253,  ...,   1.7714,  22.7452,   3.0905],\n",
      "        [ 11.4561,  12.4619,  30.7626,  ...,  -6.3859,  -9.6268,   4.4666],\n",
      "        [ -1.2083,  -3.6482,  -3.2297,  ...,  -0.5483, -15.3619, -18.1681]])\n",
      "Softmax 后的注意力权重（部分）：\n",
      " tensor([[3.2574e-10, 5.7187e-12, 5.1616e-10,  ..., 6.1236e-01, 9.2846e-05,\n",
      "         1.8327e-13],\n",
      "        [6.3670e-19, 1.1753e-11, 4.5098e-01,  ..., 4.1502e-10, 2.3044e-09,\n",
      "         1.5805e-11],\n",
      "        [6.3596e-21, 4.0021e-14, 9.9840e-01,  ..., 1.3798e-12, 3.1501e-19,\n",
      "         1.1581e-13],\n",
      "        ...,\n",
      "        [2.0997e-10, 1.9041e-11, 1.4742e-09,  ..., 7.7455e-14, 9.9509e-05,\n",
      "         2.8967e-13],\n",
      "        [4.0605e-09, 1.1102e-08, 9.8472e-01,  ..., 7.2427e-17, 2.8340e-18,\n",
      "         3.7420e-12],\n",
      "        [2.6275e-13, 2.2904e-14, 3.4806e-14,  ..., 5.0836e-13, 1.8737e-19,\n",
      "         1.1323e-20]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 打印未缩放的注意力分数\n",
    "print(\"未缩放的注意力分数（部分）：\\n\", scores[0, 0, :50, :50])\n",
    "\n",
    "# 应用 Softmax\n",
    "attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "# 打印 Softmax 后的注意力权重\n",
    "print(\"Softmax 后的注意力权重（部分）：\\n\", attention_weights[0, 0, :50, :50])\n",
    "\n",
    "# 可视化第一个批次、第一个注意力头的注意力权重\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(attention_weights[0, 0].detach().numpy(), cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title(\"Attention Weights for First Batch, First Head\")\n",
    "plt.xlabel(\"Key\")\n",
    "plt.ylabel(\"Query\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "让我们看看加入了缩放的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 50, 128]) torch.Size([32, 16, 50, 128])\n",
      "torch.Size([32, 16, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设输入维度d_model较大\n",
    "d_model = 2048\n",
    "seq_len = 50\n",
    "batch_size = 32\n",
    "num_heads = 16\n",
    "head_dim = d_model // num_heads # 128\n",
    "\n",
    "# 随机生成 Q 和 K\n",
    "Q = torch.randn(batch_size, num_heads, seq_len, head_dim)  # (32, 8, 50, 128)\n",
    "K = torch.randn(batch_size, num_heads, seq_len, head_dim)  # (32, 8, 50, 128)\n",
    "print(Q.shape, K.shape)\n",
    "\n",
    "scores = torch.matmul(Q, K.transpose(-2, -1))  # (32, 8, 50, 50)\n",
    "scores = scores / torch.sqrt(torch.tensor(head_dim, dtype=torch.float32))\n",
    "\n",
    "print(scores.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缩放的注意力分数（部分）：\n",
      " tensor([[-0.1193, -0.3991,  1.0395,  ...,  0.6206, -0.3299,  0.3740],\n",
      "        [ 1.3683,  1.5217,  0.6569,  ..., -0.4973,  1.7000, -0.7161],\n",
      "        [ 0.4921,  0.4548,  0.4633,  ..., -1.2318,  1.8076,  0.6655],\n",
      "        ...,\n",
      "        [-1.5717, -0.9738, -0.6003,  ..., -1.2817, -0.0924,  0.8348],\n",
      "        [ 1.5615,  0.3240,  0.6521,  ...,  1.4109, -0.3574, -0.0793],\n",
      "        [ 2.0136, -0.1115,  1.2173,  ...,  1.8311, -1.9042, -0.5721]])\n",
      "Softmax 后的注意力权重（部分）：\n",
      " tensor([[0.0095, 0.0071, 0.0301,  ..., 0.0198, 0.0077, 0.0155],\n",
      "        [0.0373, 0.0434, 0.0183,  ..., 0.0058, 0.0519, 0.0046],\n",
      "        [0.0176, 0.0169, 0.0171,  ..., 0.0031, 0.0655, 0.0209],\n",
      "        ...,\n",
      "        [0.0033, 0.0061, 0.0088,  ..., 0.0045, 0.0146, 0.0370],\n",
      "        [0.0482, 0.0140, 0.0194,  ..., 0.0415, 0.0071, 0.0093],\n",
      "        [0.1027, 0.0123, 0.0463,  ..., 0.0855, 0.0020, 0.0077]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 打印缩放的注意力分数\n",
    "print(\"缩放的注意力分数（部分）：\\n\", scores[0, 0, :50, :50])\n",
    "\n",
    "# 应用 Softmax\n",
    "attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "# 打印 Softmax 后的注意力权重\n",
    "print(\"Softmax 后的注意力权重（部分）：\\n\", attention_weights[0, 0, :50, :50])\n",
    "\n",
    "# 可视化第一个批次、第一个注意力头的注意力权重\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(attention_weights[0, 0].detach().numpy(), cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title(\"Attention Weights for First Batch, First Head\")\n",
    "plt.xlabel(\"Key\")\n",
    "plt.ylabel(\"Query\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "肉眼可见地，加入sqrt之后的attention weight分布更加平滑了，不像前者的图像，某些权重要么特别亮要么接近为0。这一点也不健康。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### **3. Softmax**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "注意力权重 attention 的形状： torch.Size([32, 16, 50, 50])\n",
      "注意力权重 attention 的值：\n",
      " tensor([[[[0.0095, 0.0071, 0.0301,  ..., 0.0198, 0.0077, 0.0155],\n",
      "          [0.0373, 0.0434, 0.0183,  ..., 0.0058, 0.0519, 0.0046],\n",
      "          [0.0176, 0.0169, 0.0171,  ..., 0.0031, 0.0655, 0.0209],\n",
      "          ...,\n",
      "          [0.0033, 0.0061, 0.0088,  ..., 0.0045, 0.0146, 0.0370],\n",
      "          [0.0482, 0.0140, 0.0194,  ..., 0.0415, 0.0071, 0.0093],\n",
      "          [0.1027, 0.0123, 0.0463,  ..., 0.0855, 0.0020, 0.0077]],\n",
      "\n",
      "         [[0.0313, 0.0092, 0.0049,  ..., 0.0078, 0.0305, 0.0146],\n",
      "          [0.0048, 0.0753, 0.0276,  ..., 0.0234, 0.0195, 0.0084],\n",
      "          [0.0103, 0.0117, 0.0089,  ..., 0.0168, 0.0129, 0.0097],\n",
      "          ...,\n",
      "          [0.0296, 0.0692, 0.0097,  ..., 0.0206, 0.0220, 0.0132],\n",
      "          [0.0220, 0.0283, 0.0066,  ..., 0.0108, 0.0894, 0.0013],\n",
      "          [0.0098, 0.0916, 0.0207,  ..., 0.0103, 0.0158, 0.0085]],\n",
      "\n",
      "         [[0.0296, 0.0080, 0.0059,  ..., 0.0114, 0.0198, 0.0051],\n",
      "          [0.0235, 0.0030, 0.0040,  ..., 0.0300, 0.0076, 0.0119],\n",
      "          [0.0284, 0.0126, 0.0063,  ..., 0.0010, 0.0424, 0.0026],\n",
      "          ...,\n",
      "          [0.0065, 0.0060, 0.0058,  ..., 0.0216, 0.0372, 0.0148],\n",
      "          [0.0038, 0.0431, 0.0373,  ..., 0.0065, 0.0229, 0.0052],\n",
      "          [0.0637, 0.0210, 0.0069,  ..., 0.0074, 0.0415, 0.0038]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0211, 0.0437, 0.0167,  ..., 0.0189, 0.0100, 0.0024],\n",
      "          [0.0156, 0.0119, 0.1169,  ..., 0.0053, 0.0113, 0.0292],\n",
      "          [0.0062, 0.0273, 0.0198,  ..., 0.0042, 0.0323, 0.0256],\n",
      "          ...,\n",
      "          [0.0213, 0.0164, 0.0272,  ..., 0.0259, 0.0072, 0.0127],\n",
      "          [0.0358, 0.0142, 0.0112,  ..., 0.0924, 0.0035, 0.0345],\n",
      "          [0.0188, 0.0027, 0.0084,  ..., 0.0031, 0.0048, 0.0033]],\n",
      "\n",
      "         [[0.0029, 0.0122, 0.0024,  ..., 0.0292, 0.0170, 0.0809],\n",
      "          [0.0134, 0.0241, 0.0179,  ..., 0.0050, 0.0253, 0.0282],\n",
      "          [0.0045, 0.0160, 0.0403,  ..., 0.0130, 0.0370, 0.0339],\n",
      "          ...,\n",
      "          [0.0608, 0.0093, 0.0062,  ..., 0.0092, 0.0327, 0.0099],\n",
      "          [0.0186, 0.0077, 0.0146,  ..., 0.0550, 0.0065, 0.0026],\n",
      "          [0.0084, 0.0310, 0.0018,  ..., 0.0141, 0.0599, 0.0026]],\n",
      "\n",
      "         [[0.0242, 0.0053, 0.0253,  ..., 0.0041, 0.0321, 0.0165],\n",
      "          [0.0014, 0.0348, 0.0278,  ..., 0.0142, 0.0172, 0.0038],\n",
      "          [0.0108, 0.0160, 0.0046,  ..., 0.0107, 0.0050, 0.0067],\n",
      "          ...,\n",
      "          [0.0306, 0.0729, 0.0050,  ..., 0.0069, 0.0289, 0.0034],\n",
      "          [0.0049, 0.0291, 0.0746,  ..., 0.0167, 0.0136, 0.0165],\n",
      "          [0.0348, 0.0207, 0.0988,  ..., 0.0018, 0.0197, 0.0199]]],\n",
      "\n",
      "\n",
      "        [[[0.0072, 0.0037, 0.0042,  ..., 0.0046, 0.0106, 0.0032],\n",
      "          [0.0066, 0.0099, 0.0465,  ..., 0.0181, 0.0142, 0.0105],\n",
      "          [0.0066, 0.0304, 0.0163,  ..., 0.0090, 0.0154, 0.0056],\n",
      "          ...,\n",
      "          [0.0501, 0.0033, 0.0091,  ..., 0.0064, 0.0067, 0.0110],\n",
      "          [0.0209, 0.0195, 0.0124,  ..., 0.0093, 0.0181, 0.0035],\n",
      "          [0.0184, 0.0219, 0.0048,  ..., 0.0058, 0.0488, 0.0182]],\n",
      "\n",
      "         [[0.0327, 0.0628, 0.0139,  ..., 0.0779, 0.0589, 0.0107],\n",
      "          [0.0172, 0.0057, 0.0337,  ..., 0.0040, 0.0096, 0.0152],\n",
      "          [0.0090, 0.0017, 0.0089,  ..., 0.0041, 0.0182, 0.0100],\n",
      "          ...,\n",
      "          [0.0047, 0.0309, 0.0072,  ..., 0.0250, 0.0310, 0.0367],\n",
      "          [0.0038, 0.0104, 0.0028,  ..., 0.0022, 0.0672, 0.0255],\n",
      "          [0.0026, 0.0378, 0.0253,  ..., 0.0055, 0.0023, 0.0143]],\n",
      "\n",
      "         [[0.0458, 0.0170, 0.0253,  ..., 0.0251, 0.0068, 0.0136],\n",
      "          [0.0232, 0.0204, 0.0040,  ..., 0.0020, 0.0056, 0.0106],\n",
      "          [0.0417, 0.0071, 0.0134,  ..., 0.0198, 0.0119, 0.0373],\n",
      "          ...,\n",
      "          [0.0575, 0.0050, 0.0217,  ..., 0.0146, 0.0131, 0.0084],\n",
      "          [0.0212, 0.0295, 0.0030,  ..., 0.0112, 0.0141, 0.0133],\n",
      "          [0.0032, 0.0025, 0.0693,  ..., 0.0042, 0.0319, 0.0701]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0299, 0.0099, 0.0044,  ..., 0.0453, 0.0083, 0.0101],\n",
      "          [0.0100, 0.0326, 0.0092,  ..., 0.0034, 0.0060, 0.0069],\n",
      "          [0.0139, 0.0080, 0.0175,  ..., 0.0169, 0.0077, 0.0241],\n",
      "          ...,\n",
      "          [0.0018, 0.0131, 0.0032,  ..., 0.0228, 0.0028, 0.0022],\n",
      "          [0.0298, 0.0148, 0.0232,  ..., 0.0027, 0.0106, 0.0059],\n",
      "          [0.0023, 0.0073, 0.1067,  ..., 0.0225, 0.0293, 0.0143]],\n",
      "\n",
      "         [[0.0230, 0.0231, 0.0065,  ..., 0.0180, 0.0049, 0.0451],\n",
      "          [0.0156, 0.0025, 0.0024,  ..., 0.0019, 0.0064, 0.0251],\n",
      "          [0.0114, 0.0426, 0.0042,  ..., 0.0092, 0.0159, 0.0470],\n",
      "          ...,\n",
      "          [0.0056, 0.0244, 0.0062,  ..., 0.0083, 0.0036, 0.1358],\n",
      "          [0.0022, 0.0095, 0.0391,  ..., 0.0019, 0.0094, 0.0305],\n",
      "          [0.0564, 0.0151, 0.0319,  ..., 0.0426, 0.0187, 0.0074]],\n",
      "\n",
      "         [[0.0564, 0.0800, 0.0122,  ..., 0.0054, 0.0384, 0.0510],\n",
      "          [0.0347, 0.0177, 0.0052,  ..., 0.0324, 0.0200, 0.0150],\n",
      "          [0.0027, 0.0013, 0.0022,  ..., 0.0017, 0.0165, 0.0100],\n",
      "          ...,\n",
      "          [0.0273, 0.0288, 0.0615,  ..., 0.0206, 0.0070, 0.0088],\n",
      "          [0.0132, 0.0397, 0.0228,  ..., 0.0662, 0.0085, 0.0020],\n",
      "          [0.0079, 0.0231, 0.0098,  ..., 0.0064, 0.0217, 0.0084]]],\n",
      "\n",
      "\n",
      "        [[[0.0081, 0.0121, 0.0115,  ..., 0.0048, 0.0237, 0.0075],\n",
      "          [0.0187, 0.0134, 0.0202,  ..., 0.0690, 0.0041, 0.0040],\n",
      "          [0.0190, 0.0320, 0.0099,  ..., 0.0052, 0.0124, 0.0075],\n",
      "          ...,\n",
      "          [0.0300, 0.0112, 0.0063,  ..., 0.0117, 0.0077, 0.0024],\n",
      "          [0.0068, 0.0248, 0.0180,  ..., 0.0186, 0.0089, 0.0158],\n",
      "          [0.0021, 0.0110, 0.0015,  ..., 0.0045, 0.0064, 0.0161]],\n",
      "\n",
      "         [[0.0142, 0.0042, 0.0109,  ..., 0.0319, 0.0118, 0.0236],\n",
      "          [0.0177, 0.0058, 0.0115,  ..., 0.0016, 0.0027, 0.0058],\n",
      "          [0.0069, 0.0205, 0.0038,  ..., 0.0212, 0.0353, 0.0531],\n",
      "          ...,\n",
      "          [0.0037, 0.0316, 0.0211,  ..., 0.0046, 0.0186, 0.0017],\n",
      "          [0.0013, 0.0162, 0.0895,  ..., 0.0102, 0.0110, 0.0137],\n",
      "          [0.0076, 0.0135, 0.0317,  ..., 0.0106, 0.0563, 0.0106]],\n",
      "\n",
      "         [[0.0054, 0.0015, 0.0101,  ..., 0.0084, 0.0068, 0.0035],\n",
      "          [0.0158, 0.0020, 0.0079,  ..., 0.0126, 0.0306, 0.0150],\n",
      "          [0.0032, 0.0459, 0.0126,  ..., 0.0218, 0.0090, 0.0124],\n",
      "          ...,\n",
      "          [0.0133, 0.0294, 0.0210,  ..., 0.0059, 0.0975, 0.0194],\n",
      "          [0.0388, 0.0262, 0.0101,  ..., 0.0180, 0.0181, 0.0088],\n",
      "          [0.0217, 0.0213, 0.0066,  ..., 0.0513, 0.0080, 0.0141]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0200, 0.0046, 0.0035,  ..., 0.0038, 0.0099, 0.0065],\n",
      "          [0.0116, 0.0093, 0.0096,  ..., 0.0049, 0.0048, 0.0346],\n",
      "          [0.0422, 0.0075, 0.0033,  ..., 0.0313, 0.0216, 0.0131],\n",
      "          ...,\n",
      "          [0.0017, 0.0488, 0.0134,  ..., 0.0191, 0.0341, 0.0022],\n",
      "          [0.0240, 0.0105, 0.0096,  ..., 0.0111, 0.0009, 0.0199],\n",
      "          [0.0239, 0.0157, 0.0456,  ..., 0.0074, 0.0523, 0.0422]],\n",
      "\n",
      "         [[0.0147, 0.0150, 0.0243,  ..., 0.0243, 0.0110, 0.0273],\n",
      "          [0.0119, 0.0101, 0.0481,  ..., 0.0130, 0.0120, 0.0072],\n",
      "          [0.0187, 0.0126, 0.0145,  ..., 0.0098, 0.0110, 0.0212],\n",
      "          ...,\n",
      "          [0.0231, 0.0094, 0.0291,  ..., 0.0047, 0.0020, 0.0044],\n",
      "          [0.0132, 0.0073, 0.0274,  ..., 0.0063, 0.0127, 0.0395],\n",
      "          [0.0185, 0.0125, 0.0527,  ..., 0.0096, 0.0388, 0.0022]],\n",
      "\n",
      "         [[0.0137, 0.0807, 0.0231,  ..., 0.0115, 0.0068, 0.0301],\n",
      "          [0.0199, 0.0073, 0.0290,  ..., 0.0171, 0.0374, 0.0299],\n",
      "          [0.0103, 0.0421, 0.0226,  ..., 0.0065, 0.0149, 0.0076],\n",
      "          ...,\n",
      "          [0.0023, 0.0632, 0.0065,  ..., 0.0044, 0.0071, 0.0226],\n",
      "          [0.0172, 0.0327, 0.0244,  ..., 0.0470, 0.0008, 0.0035],\n",
      "          [0.0089, 0.0164, 0.0067,  ..., 0.0190, 0.0170, 0.0104]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0064, 0.0155, 0.0015,  ..., 0.0146, 0.0134, 0.0050],\n",
      "          [0.0055, 0.1068, 0.0265,  ..., 0.0263, 0.0105, 0.0178],\n",
      "          [0.0097, 0.0087, 0.0101,  ..., 0.0089, 0.0053, 0.0225],\n",
      "          ...,\n",
      "          [0.0097, 0.0276, 0.0586,  ..., 0.0057, 0.0417, 0.0350],\n",
      "          [0.0041, 0.0055, 0.0105,  ..., 0.0353, 0.0093, 0.0052],\n",
      "          [0.0567, 0.0068, 0.1221,  ..., 0.0119, 0.0018, 0.0544]],\n",
      "\n",
      "         [[0.0507, 0.0327, 0.0092,  ..., 0.0024, 0.0099, 0.0124],\n",
      "          [0.0040, 0.0218, 0.0181,  ..., 0.0374, 0.0443, 0.0081],\n",
      "          [0.0026, 0.0332, 0.0554,  ..., 0.0431, 0.0065, 0.0101],\n",
      "          ...,\n",
      "          [0.0399, 0.0141, 0.0140,  ..., 0.0100, 0.0064, 0.0084],\n",
      "          [0.0324, 0.0058, 0.0154,  ..., 0.0147, 0.0124, 0.0045],\n",
      "          [0.0331, 0.0238, 0.0362,  ..., 0.0079, 0.0244, 0.0452]],\n",
      "\n",
      "         [[0.0022, 0.0026, 0.0107,  ..., 0.0159, 0.0114, 0.0744],\n",
      "          [0.0409, 0.0047, 0.0066,  ..., 0.0301, 0.0101, 0.0046],\n",
      "          [0.0322, 0.0046, 0.0083,  ..., 0.0026, 0.0012, 0.0055],\n",
      "          ...,\n",
      "          [0.0112, 0.0355, 0.0054,  ..., 0.0190, 0.0036, 0.0059],\n",
      "          [0.0224, 0.0622, 0.0289,  ..., 0.0176, 0.0239, 0.0063],\n",
      "          [0.0327, 0.0116, 0.0299,  ..., 0.0252, 0.0095, 0.0172]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0968, 0.0154, 0.0053,  ..., 0.0715, 0.0620, 0.0014],\n",
      "          [0.0207, 0.0212, 0.0249,  ..., 0.0132, 0.0020, 0.0975],\n",
      "          [0.0028, 0.0044, 0.0806,  ..., 0.0046, 0.0141, 0.0097],\n",
      "          ...,\n",
      "          [0.0155, 0.0330, 0.0244,  ..., 0.0112, 0.0314, 0.0034],\n",
      "          [0.0659, 0.0027, 0.0044,  ..., 0.0080, 0.0044, 0.0089],\n",
      "          [0.0093, 0.0273, 0.0150,  ..., 0.0080, 0.0083, 0.0028]],\n",
      "\n",
      "         [[0.0068, 0.0155, 0.0163,  ..., 0.0333, 0.0459, 0.0105],\n",
      "          [0.0086, 0.0051, 0.0620,  ..., 0.0249, 0.0068, 0.0047],\n",
      "          [0.0567, 0.0256, 0.0038,  ..., 0.0066, 0.0090, 0.0019],\n",
      "          ...,\n",
      "          [0.0242, 0.0589, 0.0259,  ..., 0.0053, 0.0184, 0.0051],\n",
      "          [0.0105, 0.0102, 0.0295,  ..., 0.0018, 0.0515, 0.0090],\n",
      "          [0.0191, 0.0027, 0.0220,  ..., 0.0056, 0.0067, 0.0200]],\n",
      "\n",
      "         [[0.0045, 0.0102, 0.0098,  ..., 0.0339, 0.0255, 0.0054],\n",
      "          [0.0174, 0.0040, 0.0216,  ..., 0.0174, 0.0350, 0.0439],\n",
      "          [0.0316, 0.0203, 0.0061,  ..., 0.0025, 0.0663, 0.0145],\n",
      "          ...,\n",
      "          [0.0092, 0.1398, 0.0285,  ..., 0.0399, 0.0055, 0.0231],\n",
      "          [0.0148, 0.0112, 0.0052,  ..., 0.0159, 0.0394, 0.1134],\n",
      "          [0.0046, 0.0076, 0.0108,  ..., 0.0070, 0.0147, 0.0082]]],\n",
      "\n",
      "\n",
      "        [[[0.0214, 0.0119, 0.0046,  ..., 0.0055, 0.0091, 0.0025],\n",
      "          [0.0304, 0.0244, 0.0292,  ..., 0.0060, 0.0108, 0.0047],\n",
      "          [0.0057, 0.0022, 0.0262,  ..., 0.0085, 0.0266, 0.0040],\n",
      "          ...,\n",
      "          [0.0211, 0.0101, 0.0372,  ..., 0.0228, 0.0482, 0.0055],\n",
      "          [0.0031, 0.0078, 0.3857,  ..., 0.0041, 0.0026, 0.0163],\n",
      "          [0.0051, 0.0179, 0.0080,  ..., 0.0059, 0.0201, 0.0027]],\n",
      "\n",
      "         [[0.0193, 0.0070, 0.0881,  ..., 0.1005, 0.0083, 0.0095],\n",
      "          [0.0310, 0.0165, 0.0097,  ..., 0.0047, 0.0063, 0.0035],\n",
      "          [0.0029, 0.0029, 0.0215,  ..., 0.0150, 0.0303, 0.0022],\n",
      "          ...,\n",
      "          [0.0076, 0.0280, 0.0039,  ..., 0.0111, 0.0084, 0.0295],\n",
      "          [0.0040, 0.0328, 0.0078,  ..., 0.0618, 0.0021, 0.0169],\n",
      "          [0.0285, 0.0141, 0.0098,  ..., 0.0093, 0.0138, 0.0013]],\n",
      "\n",
      "         [[0.0401, 0.0167, 0.0507,  ..., 0.0102, 0.0336, 0.0167],\n",
      "          [0.0047, 0.0046, 0.0006,  ..., 0.0072, 0.0705, 0.1692],\n",
      "          [0.0185, 0.0142, 0.0103,  ..., 0.0071, 0.0486, 0.0042],\n",
      "          ...,\n",
      "          [0.0151, 0.0496, 0.0490,  ..., 0.0529, 0.0110, 0.0066],\n",
      "          [0.0961, 0.0084, 0.0092,  ..., 0.0028, 0.0256, 0.0073],\n",
      "          [0.0039, 0.0183, 0.0262,  ..., 0.0046, 0.0078, 0.0297]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0108, 0.0116, 0.0274,  ..., 0.0062, 0.0274, 0.0037],\n",
      "          [0.0219, 0.0152, 0.0266,  ..., 0.0218, 0.0061, 0.0100],\n",
      "          [0.0075, 0.0188, 0.0343,  ..., 0.0057, 0.0066, 0.1424],\n",
      "          ...,\n",
      "          [0.0032, 0.0871, 0.0099,  ..., 0.0134, 0.0054, 0.0382],\n",
      "          [0.0072, 0.0155, 0.0330,  ..., 0.0097, 0.0030, 0.0038],\n",
      "          [0.0141, 0.0041, 0.0697,  ..., 0.0077, 0.0060, 0.0038]],\n",
      "\n",
      "         [[0.0169, 0.0016, 0.0063,  ..., 0.0344, 0.0495, 0.0183],\n",
      "          [0.0101, 0.0100, 0.0136,  ..., 0.0141, 0.0090, 0.0038],\n",
      "          [0.0097, 0.0175, 0.0169,  ..., 0.0273, 0.0048, 0.0227],\n",
      "          ...,\n",
      "          [0.0127, 0.0195, 0.0094,  ..., 0.0041, 0.0120, 0.0046],\n",
      "          [0.0059, 0.0164, 0.0401,  ..., 0.0142, 0.0226, 0.0191],\n",
      "          [0.0155, 0.0940, 0.0402,  ..., 0.0140, 0.0199, 0.0155]],\n",
      "\n",
      "         [[0.0120, 0.0078, 0.0028,  ..., 0.0364, 0.0179, 0.0181],\n",
      "          [0.0157, 0.0076, 0.0307,  ..., 0.0206, 0.0169, 0.0225],\n",
      "          [0.0072, 0.0809, 0.0085,  ..., 0.0180, 0.0157, 0.0158],\n",
      "          ...,\n",
      "          [0.0184, 0.0037, 0.0864,  ..., 0.0452, 0.0024, 0.0214],\n",
      "          [0.0111, 0.0552, 0.0075,  ..., 0.0396, 0.0647, 0.0262],\n",
      "          [0.0165, 0.0092, 0.0112,  ..., 0.0133, 0.0138, 0.0243]]],\n",
      "\n",
      "\n",
      "        [[[0.0033, 0.0021, 0.0105,  ..., 0.0387, 0.0024, 0.0354],\n",
      "          [0.0102, 0.0121, 0.0304,  ..., 0.0573, 0.0051, 0.0441],\n",
      "          [0.0176, 0.0090, 0.0176,  ..., 0.0104, 0.0064, 0.0039],\n",
      "          ...,\n",
      "          [0.0049, 0.0060, 0.0179,  ..., 0.0063, 0.0175, 0.0326],\n",
      "          [0.0369, 0.0197, 0.0025,  ..., 0.0077, 0.0423, 0.0166],\n",
      "          [0.0114, 0.0045, 0.0411,  ..., 0.0259, 0.0206, 0.0204]],\n",
      "\n",
      "         [[0.0037, 0.0142, 0.0033,  ..., 0.0048, 0.0092, 0.0091],\n",
      "          [0.0250, 0.0167, 0.0018,  ..., 0.0035, 0.0111, 0.0747],\n",
      "          [0.0095, 0.0238, 0.0319,  ..., 0.0131, 0.0013, 0.0051],\n",
      "          ...,\n",
      "          [0.0150, 0.0037, 0.0061,  ..., 0.0039, 0.0023, 0.0221],\n",
      "          [0.0050, 0.0789, 0.0022,  ..., 0.0195, 0.0117, 0.0261],\n",
      "          [0.0101, 0.0037, 0.0268,  ..., 0.0333, 0.0261, 0.0083]],\n",
      "\n",
      "         [[0.0296, 0.0031, 0.0033,  ..., 0.0264, 0.0026, 0.0136],\n",
      "          [0.0097, 0.0035, 0.0217,  ..., 0.0113, 0.0209, 0.0179],\n",
      "          [0.0102, 0.0128, 0.0117,  ..., 0.0292, 0.0032, 0.0244],\n",
      "          ...,\n",
      "          [0.0088, 0.0052, 0.0550,  ..., 0.0120, 0.0055, 0.0042],\n",
      "          [0.0155, 0.0458, 0.0066,  ..., 0.0311, 0.0047, 0.0095],\n",
      "          [0.0699, 0.0145, 0.0127,  ..., 0.0557, 0.0029, 0.0339]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0034, 0.0105, 0.0050,  ..., 0.0046, 0.0066, 0.0044],\n",
      "          [0.0083, 0.0135, 0.0085,  ..., 0.0133, 0.0029, 0.0055],\n",
      "          [0.0099, 0.0144, 0.0247,  ..., 0.0132, 0.0116, 0.0498],\n",
      "          ...,\n",
      "          [0.0649, 0.0239, 0.0054,  ..., 0.0041, 0.0023, 0.0028],\n",
      "          [0.0070, 0.0460, 0.0844,  ..., 0.0226, 0.0089, 0.0318],\n",
      "          [0.0013, 0.0251, 0.0096,  ..., 0.0036, 0.0012, 0.0078]],\n",
      "\n",
      "         [[0.0320, 0.0074, 0.0015,  ..., 0.0295, 0.0058, 0.0321],\n",
      "          [0.0062, 0.0041, 0.0062,  ..., 0.0047, 0.0049, 0.0066],\n",
      "          [0.0192, 0.1338, 0.0118,  ..., 0.0300, 0.0114, 0.0038],\n",
      "          ...,\n",
      "          [0.0356, 0.0106, 0.0964,  ..., 0.0134, 0.0196, 0.0259],\n",
      "          [0.0122, 0.0461, 0.0156,  ..., 0.0082, 0.0090, 0.0566],\n",
      "          [0.0114, 0.0155, 0.0264,  ..., 0.0131, 0.0119, 0.0084]],\n",
      "\n",
      "         [[0.0222, 0.0207, 0.0187,  ..., 0.0573, 0.0360, 0.0023],\n",
      "          [0.0103, 0.0224, 0.0107,  ..., 0.0028, 0.0092, 0.0354],\n",
      "          [0.0824, 0.0067, 0.0032,  ..., 0.0078, 0.0027, 0.0172],\n",
      "          ...,\n",
      "          [0.0360, 0.0638, 0.0121,  ..., 0.0202, 0.0040, 0.0062],\n",
      "          [0.0185, 0.0185, 0.0051,  ..., 0.0072, 0.0281, 0.0285],\n",
      "          [0.0644, 0.0031, 0.0097,  ..., 0.0094, 0.0100, 0.0103]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "attention = F.softmax(scores, dim=-1)  # (batch_size, num_heads, seq_len, seq_len)\n",
    "print(\"注意力权重 attention 的形状：\", attention.shape)\n",
    "print(\"注意力权重 attention 的值：\\n\", attention)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **解释**：\n",
    "  - 对最后一个维度（`seq_len`）进行softmax，得到归一化的注意力权重。\n",
    "  - 注意力权重的形状为`(batch_size, num_heads, seq_len, seq_len)`。\n",
    "\n",
    "**注意力权重用于衡量输入序列中每个位置对其他位置的重要性，并指导模型如何聚合信息。**\n",
    "\n",
    "---\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 加权求和 🐱 使用注意力权重对 V 进行加权求和"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与 `V` 进行加权求和是为了根据注意力权重动态提取与当前查询最相关的信息，增强模型的上下文感知能力和特征提取能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 16, 50, 32]), torch.Size([32, 16, 50, 50]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape, attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加权求和后的输出 output 的形状： torch.Size([32, 16, 50, 32])\n",
      "加权求和后的输出 output 的值：\n",
      " tensor([[[[-1.2230e-01, -4.4290e-02, -6.7366e-02,  ..., -1.2116e-01,\n",
      "            5.2628e-01,  9.5569e-01],\n",
      "          [-2.1048e-01,  1.4416e-01, -1.8828e-02,  ..., -7.2201e-02,\n",
      "            6.6881e-01,  8.9801e-01],\n",
      "          [-8.1148e-02,  2.2151e-01, -1.0284e-02,  ...,  5.5813e-02,\n",
      "            6.3798e-01,  9.4279e-01],\n",
      "          ...,\n",
      "          [ 2.1776e-02, -1.9294e-02, -1.7315e-01,  ..., -2.5382e-01,\n",
      "            3.7755e-01,  1.0096e+00],\n",
      "          [-1.2029e-01,  1.7883e-01, -8.0604e-02,  ..., -1.0929e-01,\n",
      "            5.5525e-01,  1.0154e+00],\n",
      "          [ 7.2097e-02,  7.0224e-02, -1.8325e-01,  ..., -1.8521e-01,\n",
      "            5.8036e-01,  9.4113e-01]],\n",
      "\n",
      "         [[ 1.4697e-01,  4.1431e-01, -1.8531e-02,  ...,  4.4623e-01,\n",
      "           -2.9548e-02, -8.0245e-02],\n",
      "          [ 4.3757e-01,  5.8278e-01, -1.5764e-01,  ...,  2.9908e-01,\n",
      "           -8.0500e-02, -2.3957e-01],\n",
      "          [ 2.3654e-01,  5.9856e-01,  7.9787e-03,  ...,  3.2911e-01,\n",
      "           -9.5040e-03, -2.1814e-01],\n",
      "          ...,\n",
      "          [ 2.0739e-01,  4.9456e-01,  1.3983e-01,  ...,  2.6963e-01,\n",
      "           -1.9815e-01, -1.2610e-01],\n",
      "          [ 2.9450e-01,  5.4196e-01,  3.2325e-03,  ...,  2.5809e-01,\n",
      "            2.3785e-03, -1.5381e-01],\n",
      "          [ 2.0058e-01,  5.1969e-01, -3.6160e-02,  ...,  2.6793e-01,\n",
      "           -6.3334e-02, -2.0620e-01]],\n",
      "\n",
      "         [[ 2.7277e-01, -2.1692e-01,  4.1147e-01,  ..., -1.1685e-01,\n",
      "            6.0162e-01,  1.2149e-01],\n",
      "          [ 1.6224e-01, -2.8152e-01,  6.4448e-01,  ...,  1.5935e-01,\n",
      "            6.0798e-01, -3.5116e-02],\n",
      "          [ 1.4587e-01, -1.4460e-01,  5.3476e-01,  ...,  4.0427e-02,\n",
      "            6.1064e-01, -1.6198e-01],\n",
      "          ...,\n",
      "          [ 1.6635e-01, -1.2428e-01,  3.4495e-01,  ..., -3.3434e-01,\n",
      "            4.9488e-01,  1.6040e-01],\n",
      "          [ 1.7923e-01, -3.5799e-01,  6.0920e-01,  ...,  5.1644e-02,\n",
      "            5.6701e-01,  1.1298e-01],\n",
      "          [-3.8606e-02, -7.8836e-02,  5.8328e-01,  ...,  5.5589e-02,\n",
      "            6.9963e-01,  7.9705e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7429e-01,  2.1141e-01,  2.4807e-01,  ..., -3.4366e-01,\n",
      "            2.9088e-02, -3.6579e-01],\n",
      "          [ 8.9633e-02,  3.0545e-01,  2.9343e-01,  ..., -3.1286e-01,\n",
      "            1.2043e-01, -2.6650e-01],\n",
      "          [ 1.6267e-01,  2.8564e-01,  2.0452e-01,  ..., -3.8649e-01,\n",
      "            7.9468e-02, -3.0036e-01],\n",
      "          ...,\n",
      "          [ 2.7772e-01,  1.5964e-01,  2.7529e-01,  ..., -2.7040e-01,\n",
      "            3.8700e-02, -1.2246e-01],\n",
      "          [ 3.0100e-01,  1.1137e-01,  1.5915e-01,  ..., -5.8136e-01,\n",
      "            1.4073e-01, -4.3432e-01],\n",
      "          [ 2.6646e-01,  2.0234e-01,  4.0144e-01,  ..., -5.6996e-01,\n",
      "            8.4392e-02, -5.3718e-01]],\n",
      "\n",
      "         [[-1.5602e-01, -3.2005e-01, -1.1844e-01,  ..., -2.9774e-01,\n",
      "           -4.1100e-01, -1.8244e-01],\n",
      "          [-7.2376e-02, -1.2830e-01, -6.9131e-03,  ..., -4.1578e-01,\n",
      "           -4.0950e-01, -5.8741e-02],\n",
      "          [ 2.8452e-02, -1.5772e-01,  1.4784e-01,  ..., -3.0665e-01,\n",
      "           -4.5434e-01, -1.8455e-01],\n",
      "          ...,\n",
      "          [-5.9990e-02, -6.4536e-02,  1.0858e-01,  ..., -1.7199e-01,\n",
      "           -4.2967e-01, -1.5208e-01],\n",
      "          [-5.1970e-02, -1.7683e-02, -7.0932e-03,  ..., -1.8561e-01,\n",
      "           -4.6510e-01,  1.5796e-02],\n",
      "          [ 6.0795e-02, -3.7314e-01, -2.1706e-01,  ..., -1.6264e-01,\n",
      "           -4.4491e-01,  2.0293e-01]],\n",
      "\n",
      "         [[-5.2189e-01,  3.9772e-01,  1.5034e-01,  ...,  5.9550e-01,\n",
      "           -8.5671e-01,  5.8643e-03],\n",
      "          [-3.4172e-01,  4.4718e-01,  1.5923e-01,  ...,  5.7108e-01,\n",
      "           -7.9009e-01,  6.5470e-02],\n",
      "          [-1.4593e-01,  3.6151e-01,  2.9253e-01,  ...,  7.3706e-01,\n",
      "           -6.5795e-01,  4.9525e-02],\n",
      "          ...,\n",
      "          [-3.3429e-01,  4.7213e-01,  3.3566e-01,  ...,  7.9938e-01,\n",
      "           -7.0981e-01, -6.2850e-02],\n",
      "          [-2.5752e-01,  6.0416e-01,  1.2781e-01,  ...,  7.1458e-01,\n",
      "           -7.6658e-01,  8.8841e-02],\n",
      "          [-4.7043e-01,  3.5432e-01,  6.2789e-02,  ...,  6.1128e-01,\n",
      "           -8.1487e-01, -1.0308e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.9870e-02,  2.6423e-02,  6.4091e-03,  ...,  5.4730e-03,\n",
      "            3.4785e-01,  8.9127e-01],\n",
      "          [-5.7267e-02,  7.2505e-02, -1.5721e-02,  ..., -1.0479e-01,\n",
      "            5.7568e-01,  5.8504e-01],\n",
      "          [-1.1365e-01,  3.1771e-03, -3.4171e-02,  ..., -8.1737e-02,\n",
      "            4.2189e-01,  8.9328e-01],\n",
      "          ...,\n",
      "          [ 4.1677e-02,  1.2969e-01, -1.4689e-01,  ...,  4.8233e-02,\n",
      "            4.0035e-01,  8.1266e-01],\n",
      "          [-9.2183e-02,  8.8243e-02, -5.7104e-02,  ..., -7.1913e-02,\n",
      "            4.2544e-01,  8.2692e-01],\n",
      "          [-1.2518e-01,  3.9065e-02, -1.3326e-01,  ..., -1.2693e-01,\n",
      "            4.1722e-01,  8.6418e-01]],\n",
      "\n",
      "         [[-4.0573e-02,  5.3183e-01, -1.6225e-01,  ...,  2.9259e-01,\n",
      "           -8.9668e-02, -1.7226e-01],\n",
      "          [ 4.0020e-02,  6.5177e-01, -1.5299e-01,  ...,  4.7688e-01,\n",
      "           -7.9847e-02, -1.5244e-01],\n",
      "          [-8.1694e-02,  8.9611e-01, -2.4174e-01,  ...,  4.0787e-01,\n",
      "           -2.4949e-01, -1.5220e-01],\n",
      "          ...,\n",
      "          [-1.6135e-02,  5.6564e-01, -1.6029e-01,  ...,  4.2242e-01,\n",
      "           -5.0433e-02, -2.6236e-01],\n",
      "          [-1.2534e-01,  4.7220e-01, -1.6676e-01,  ...,  2.2909e-01,\n",
      "           -1.4669e-01, -1.4742e-01],\n",
      "          [-1.7019e-01,  8.4379e-01, -2.5503e-01,  ...,  6.9086e-01,\n",
      "            2.5133e-02, -1.7727e-01]],\n",
      "\n",
      "         [[-3.7137e-02, -4.5460e-01,  6.3936e-01,  ..., -1.3444e-01,\n",
      "            4.7926e-01,  8.6240e-02],\n",
      "          [-5.4634e-02, -2.9354e-01,  3.5716e-01,  ..., -8.7207e-02,\n",
      "            5.0167e-01,  1.2181e-01],\n",
      "          [-6.6686e-03, -4.4061e-01,  4.3543e-01,  ..., -2.8682e-02,\n",
      "            4.9688e-01,  1.9758e-01],\n",
      "          ...,\n",
      "          [ 1.7278e-02, -2.8219e-01,  5.3847e-01,  ..., -1.0630e-01,\n",
      "            4.4761e-01,  1.4604e-01],\n",
      "          [ 1.1280e-01, -3.7135e-01,  4.6319e-01,  ..., -2.2361e-02,\n",
      "            7.1863e-01, -2.6145e-02],\n",
      "          [ 1.1741e-01, -4.5808e-01,  5.6396e-01,  ..., -1.3966e-01,\n",
      "            5.4506e-01,  1.6010e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3450e-01,  3.3352e-01,  1.5160e-01,  ..., -2.2504e-01,\n",
      "            2.3378e-01, -2.3647e-01],\n",
      "          [ 2.1029e-01,  3.3824e-01,  3.8284e-01,  ..., -2.7348e-01,\n",
      "            1.4614e-01, -3.6731e-01],\n",
      "          [ 1.1136e-01,  2.9569e-01,  5.1659e-01,  ..., -4.2777e-02,\n",
      "            2.5858e-01, -3.3876e-01],\n",
      "          ...,\n",
      "          [ 2.8106e-01,  2.4207e-01,  3.3593e-01,  ..., -1.9001e-01,\n",
      "            1.1879e-01, -2.6073e-01],\n",
      "          [ 4.3011e-02,  2.8502e-01,  4.2922e-01,  ..., -1.0811e-01,\n",
      "            2.0535e-01, -2.9354e-01],\n",
      "          [ 1.9816e-01,  4.3688e-01,  4.0905e-01,  ..., -2.6959e-01,\n",
      "            3.0933e-01, -3.0977e-01]],\n",
      "\n",
      "         [[ 4.5283e-01, -3.1648e-01, -3.2187e-01,  ..., -2.8829e-01,\n",
      "           -4.6071e-01, -1.5032e-02],\n",
      "          [ 5.7718e-02, -4.0966e-01, -2.1728e-01,  ..., -1.7356e-01,\n",
      "           -4.2519e-01, -1.1817e-01],\n",
      "          [ 1.9386e-01, -2.3223e-01, -2.8908e-01,  ..., -3.0294e-02,\n",
      "           -5.0226e-01,  2.8145e-02],\n",
      "          ...,\n",
      "          [ 5.0585e-01, -4.1625e-01, -3.3337e-01,  ..., -1.0665e-01,\n",
      "           -1.5488e-01, -1.0709e-01],\n",
      "          [ 3.6148e-01, -2.4512e-01, -1.3369e-01,  ...,  1.1557e-01,\n",
      "           -3.1784e-01, -1.6114e-01],\n",
      "          [ 1.5769e-01, -2.0555e-01, -3.0486e-01,  ..., -1.8152e-01,\n",
      "           -6.3697e-01,  1.4892e-01]],\n",
      "\n",
      "         [[-3.6230e-01,  3.3266e-01,  3.9144e-02,  ...,  6.1881e-01,\n",
      "           -7.6860e-01, -9.7469e-02],\n",
      "          [-4.5328e-01,  4.0484e-01, -7.2101e-04,  ...,  6.1751e-01,\n",
      "           -8.5502e-01,  4.1565e-02],\n",
      "          [-4.6625e-01,  5.3271e-01,  1.7270e-01,  ...,  4.5302e-01,\n",
      "           -8.7917e-01,  1.4790e-02],\n",
      "          ...,\n",
      "          [-5.1480e-01,  1.8690e-01,  1.3651e-01,  ...,  3.1288e-01,\n",
      "           -8.1204e-01, -1.5603e-01],\n",
      "          [-4.2533e-01,  3.3605e-01, -2.0658e-02,  ...,  5.2672e-01,\n",
      "           -8.2474e-01,  9.2212e-02],\n",
      "          [-7.1663e-01,  3.3629e-01,  3.6889e-02,  ...,  5.7305e-01,\n",
      "           -7.2896e-01,  1.9242e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5507e-02,  3.9353e-01, -2.4246e-01,  ...,  4.4986e-01,\n",
      "            5.0181e-01,  7.5656e-01],\n",
      "          [-3.8426e-01,  2.1132e-01, -1.1136e-01,  ..., -1.1305e-01,\n",
      "            3.7553e-01,  8.7559e-01],\n",
      "          [-3.5518e-01,  1.5072e-01,  8.1040e-03,  ..., -8.4239e-02,\n",
      "            4.1434e-01,  8.1385e-01],\n",
      "          ...,\n",
      "          [-1.8575e-01,  4.9532e-02,  9.7863e-02,  ..., -5.8069e-02,\n",
      "            4.1910e-01,  8.3546e-01],\n",
      "          [-1.1208e-01,  1.3565e-01, -2.2604e-01,  ..., -1.5529e-01,\n",
      "            2.5464e-01,  7.9509e-01],\n",
      "          [-9.9159e-02,  2.7657e-01, -1.6276e-01,  ...,  6.2660e-02,\n",
      "            3.6529e-01,  7.5527e-01]],\n",
      "\n",
      "         [[ 4.4097e-02,  5.9215e-01, -2.9677e-02,  ...,  3.5363e-01,\n",
      "           -3.4484e-01, -9.3088e-02],\n",
      "          [ 8.6484e-02,  4.7978e-01,  4.7550e-02,  ...,  2.1011e-01,\n",
      "           -4.1562e-01, -1.3700e-01],\n",
      "          [-4.1544e-02,  5.5841e-01, -1.1558e-01,  ...,  3.7332e-01,\n",
      "           -1.8289e-01, -1.5956e-01],\n",
      "          ...,\n",
      "          [-1.7935e-02,  5.8984e-01, -2.6075e-02,  ...,  4.5810e-01,\n",
      "           -3.3984e-01,  1.1021e-01],\n",
      "          [-5.2880e-02,  7.3573e-01, -7.0195e-02,  ...,  1.9213e-01,\n",
      "           -1.3791e-01,  1.3231e-01],\n",
      "          [ 8.3311e-02,  5.0615e-01, -1.3642e-01,  ...,  3.3365e-01,\n",
      "           -3.7208e-01, -2.0785e-01]],\n",
      "\n",
      "         [[ 4.2512e-02, -4.5408e-01,  5.4060e-01,  ..., -7.1569e-02,\n",
      "            3.6008e-01,  1.1752e-01],\n",
      "          [ 4.6720e-02, -4.9240e-01,  6.7833e-01,  ...,  5.5215e-02,\n",
      "            4.3445e-01,  1.7987e-01],\n",
      "          [-1.0562e-02, -4.5655e-01,  4.4789e-01,  ...,  7.2165e-02,\n",
      "            5.0020e-01,  2.9740e-01],\n",
      "          ...,\n",
      "          [ 2.4593e-01, -5.5829e-01,  6.8489e-01,  ..., -1.7643e-02,\n",
      "            3.7386e-01,  1.5459e-01],\n",
      "          [ 7.5115e-03, -5.2775e-01,  6.6848e-01,  ...,  6.3015e-02,\n",
      "            3.1170e-01,  2.1780e-01],\n",
      "          [ 3.2932e-01, -5.8781e-01,  5.7721e-01,  ...,  1.0805e-01,\n",
      "            2.8230e-01,  4.0322e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0446e-02,  2.0522e-01,  2.7377e-01,  ..., -2.5940e-01,\n",
      "            1.9401e-01, -1.3261e-01],\n",
      "          [ 1.6436e-01,  2.6124e-01,  1.8518e-01,  ..., -2.6626e-01,\n",
      "            2.0577e-01, -1.0938e-02],\n",
      "          [ 1.3420e-01,  9.8744e-02,  2.8682e-01,  ..., -1.0379e-01,\n",
      "            1.7927e-01, -5.8746e-02],\n",
      "          ...,\n",
      "          [-1.0771e-01,  1.4596e-01,  3.1661e-01,  ..., -2.2531e-01,\n",
      "            1.2041e-01, -1.4076e-01],\n",
      "          [-7.8714e-02,  1.3585e-02,  2.4527e-01,  ..., -2.0196e-01,\n",
      "            1.2266e-01, -1.7373e-01],\n",
      "          [ 3.2294e-02,  2.3678e-01,  3.8854e-01,  ..., -2.4451e-01,\n",
      "            2.1862e-01,  1.1198e-01]],\n",
      "\n",
      "         [[ 2.4960e-01,  1.3180e-01, -2.1113e-01,  ..., -3.3008e-02,\n",
      "           -1.8635e-01, -1.8500e-01],\n",
      "          [ 1.7302e-01, -1.4007e-01, -2.2519e-01,  ..., -3.2604e-01,\n",
      "           -3.8172e-01,  2.7949e-02],\n",
      "          [ 2.4953e-01, -9.7273e-02, -2.1417e-01,  ..., -1.2947e-01,\n",
      "           -3.5875e-01, -2.4106e-02],\n",
      "          ...,\n",
      "          [ 9.4241e-02,  8.5266e-02, -1.8459e-01,  ..., -2.4348e-01,\n",
      "           -5.4259e-01, -2.7789e-02],\n",
      "          [ 2.0500e-01, -1.5403e-01, -2.8039e-01,  ..., -2.4341e-01,\n",
      "           -3.6178e-01,  1.5969e-01],\n",
      "          [ 1.5757e-01,  1.3564e-01, -1.3242e-01,  ..., -3.5092e-01,\n",
      "           -3.4930e-01, -9.8897e-02]],\n",
      "\n",
      "         [[-3.7445e-01,  3.1117e-01,  8.5526e-02,  ...,  5.8695e-01,\n",
      "           -7.7876e-01, -5.5603e-02],\n",
      "          [-2.0144e-01,  3.7869e-01,  2.7797e-02,  ...,  5.6570e-01,\n",
      "           -9.2519e-01,  7.9545e-02],\n",
      "          [-3.6946e-01,  3.4217e-01,  1.8841e-01,  ...,  5.0055e-01,\n",
      "           -8.3467e-01, -7.2056e-02],\n",
      "          ...,\n",
      "          [-1.1787e-01,  2.6773e-01,  1.9604e-01,  ...,  7.1790e-01,\n",
      "           -6.8971e-01,  3.0510e-01],\n",
      "          [-3.6212e-01,  2.5042e-01, -4.9653e-02,  ...,  5.4247e-01,\n",
      "           -9.5845e-01,  3.8714e-02],\n",
      "          [-3.5288e-01,  1.8678e-01, -1.7018e-01,  ...,  4.8083e-01,\n",
      "           -7.9872e-01,  8.4587e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3985e-01,  1.3030e-01, -2.8631e-04,  ..., -2.3125e-01,\n",
      "            4.6310e-01,  8.0293e-01],\n",
      "          [ 5.5117e-02,  1.2522e-01,  4.3623e-02,  ..., -1.3274e-01,\n",
      "            4.2613e-01,  7.1031e-01],\n",
      "          [ 5.9522e-02,  1.7358e-01, -3.4225e-02,  ..., -3.7117e-01,\n",
      "            3.6101e-01,  7.2122e-01],\n",
      "          ...,\n",
      "          [-1.1047e-01,  1.1862e-01,  4.9836e-03,  ..., -3.2938e-01,\n",
      "            4.8353e-01,  6.5593e-01],\n",
      "          [-2.2716e-01, -7.8609e-02,  4.4663e-02,  ..., -4.8290e-01,\n",
      "            4.3960e-01,  6.1781e-01],\n",
      "          [ 3.5661e-02,  4.1253e-02,  3.4884e-02,  ..., -1.5360e-01,\n",
      "            4.0625e-01,  6.7161e-01]],\n",
      "\n",
      "         [[ 4.4787e-01,  8.1289e-01, -2.5212e-01,  ...,  3.2024e-01,\n",
      "           -2.7734e-01,  6.8206e-02],\n",
      "          [ 3.2128e-01,  7.0120e-01, -1.9220e-01,  ...,  1.8396e-01,\n",
      "           -2.5718e-01, -1.8233e-01],\n",
      "          [ 6.6442e-02,  8.9785e-01, -4.4262e-02,  ...,  1.5608e-02,\n",
      "           -2.3342e-01, -1.8095e-01],\n",
      "          ...,\n",
      "          [ 3.1477e-01,  5.0861e-01,  1.5927e-02,  ..., -1.8511e-02,\n",
      "           -1.8637e-01, -2.0383e-01],\n",
      "          [ 3.6728e-01,  6.3616e-01, -2.6544e-01,  ...,  2.2809e-01,\n",
      "           -2.3171e-01, -1.2811e-01],\n",
      "          [ 4.5121e-01,  8.2571e-01, -1.4427e-01,  ...,  2.4293e-01,\n",
      "           -2.1713e-01, -7.8563e-02]],\n",
      "\n",
      "         [[ 2.2685e-01, -2.8397e-01,  4.4046e-01,  ..., -2.4283e-01,\n",
      "            1.2900e-01,  4.9991e-01],\n",
      "          [-1.5836e-01, -1.9529e-01,  5.0905e-01,  ...,  7.6808e-02,\n",
      "            5.5564e-01,  3.7241e-01],\n",
      "          [-4.4626e-02, -1.0305e-01,  6.6560e-01,  ..., -7.9416e-02,\n",
      "            3.2268e-01,  2.3069e-01],\n",
      "          ...,\n",
      "          [-8.9885e-03, -2.1351e-01,  6.7415e-01,  ...,  3.0308e-02,\n",
      "            3.9559e-01,  3.1482e-01],\n",
      "          [-4.4576e-02, -1.3767e-01,  6.4417e-01,  ...,  1.4621e-01,\n",
      "            4.8696e-01,  2.6409e-01],\n",
      "          [ 7.6865e-02, -1.9983e-01,  7.9061e-01,  ..., -6.8038e-02,\n",
      "            5.5180e-01,  2.9416e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.8316e-03,  1.5587e-01,  3.2463e-01,  ..., -2.3717e-01,\n",
      "            1.8525e-01, -3.0287e-01],\n",
      "          [-5.0216e-02,  4.0557e-01,  4.7184e-01,  ..., -2.6171e-01,\n",
      "            3.5887e-01, -7.8541e-02],\n",
      "          [ 1.1250e-02,  3.3783e-01,  3.2264e-01,  ..., -2.7383e-01,\n",
      "            1.4676e-01, -2.4143e-01],\n",
      "          ...,\n",
      "          [ 7.4861e-02, -6.1040e-02,  3.6966e-01,  ..., -2.0174e-01,\n",
      "            4.2448e-01, -2.7741e-01],\n",
      "          [ 1.0788e-01,  3.1908e-01,  4.6777e-01,  ..., -6.3629e-01,\n",
      "            1.7614e-01, -4.1449e-01],\n",
      "          [ 1.1915e-01,  1.6560e-01,  4.0185e-01,  ..., -4.1493e-01,\n",
      "            1.2251e-01, -2.1519e-01]],\n",
      "\n",
      "         [[-5.6704e-02, -5.1649e-02, -2.4802e-01,  ..., -9.0179e-02,\n",
      "           -6.3070e-01, -1.8874e-01],\n",
      "          [ 5.2184e-02, -1.1457e-01, -2.3492e-01,  ..., -2.2327e-01,\n",
      "           -3.4971e-01, -1.0381e-01],\n",
      "          [ 5.4118e-03, -1.0276e-01, -2.8929e-01,  ..., -1.2921e-01,\n",
      "           -5.2656e-01, -1.1682e-01],\n",
      "          ...,\n",
      "          [-5.3440e-02, -1.1047e-01, -1.0543e-01,  ..., -3.2922e-02,\n",
      "           -3.7900e-01, -9.6290e-02],\n",
      "          [ 6.0652e-02, -2.2215e-02, -1.8693e-01,  ..., -1.1834e-01,\n",
      "           -5.6626e-01, -2.7186e-01],\n",
      "          [-3.3873e-02,  1.5811e-01, -3.2819e-01,  ..., -1.9588e-02,\n",
      "           -4.0532e-01, -8.9607e-02]],\n",
      "\n",
      "         [[-3.6235e-01,  5.0065e-01, -1.6025e-01,  ...,  6.2178e-01,\n",
      "           -6.6193e-01,  2.2083e-01],\n",
      "          [-3.7912e-01,  5.6523e-01, -1.4540e-01,  ...,  6.0885e-01,\n",
      "           -4.1087e-01, -1.3350e-01],\n",
      "          [-5.6921e-01,  5.0690e-01, -1.7713e-01,  ...,  6.1387e-01,\n",
      "           -6.7385e-01, -1.7395e-01],\n",
      "          ...,\n",
      "          [-3.4076e-01,  3.4361e-01,  9.3993e-02,  ...,  6.5525e-01,\n",
      "           -4.8044e-01,  1.0979e-01],\n",
      "          [-4.1100e-01,  2.9167e-01, -2.1942e-01,  ...,  5.3634e-01,\n",
      "           -5.4617e-01,  4.0036e-02],\n",
      "          [-3.8952e-01,  2.9190e-01, -4.2542e-02,  ...,  6.0386e-01,\n",
      "           -5.7062e-01, -1.1234e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.3513e-01,  6.3595e-02,  8.7916e-02,  ..., -2.9061e-01,\n",
      "            3.5546e-01,  8.5630e-01],\n",
      "          [-4.8686e-01, -6.7585e-02, -5.3916e-02,  ...,  3.7886e-02,\n",
      "            4.3376e-01,  6.9684e-01],\n",
      "          [-2.9158e-01,  1.6617e-01,  1.3979e-01,  ..., -1.8112e-01,\n",
      "            4.0726e-01,  8.5986e-01],\n",
      "          ...,\n",
      "          [-1.3877e-01,  1.6558e-01,  4.8986e-03,  ..., -2.0106e-01,\n",
      "            3.6479e-01,  8.7966e-01],\n",
      "          [ 4.6605e-02,  5.4701e-01,  1.9161e-01,  ..., -2.8040e-01,\n",
      "            2.0878e-01,  8.1283e-01],\n",
      "          [-2.6330e-01, -1.1723e-01,  1.0029e-01,  ..., -3.4801e-01,\n",
      "            1.7558e-01,  5.8764e-01]],\n",
      "\n",
      "         [[ 2.0873e-01,  5.9572e-01, -8.8753e-02,  ...,  2.5020e-01,\n",
      "           -5.9941e-02,  7.6128e-02],\n",
      "          [-9.1764e-02,  6.2644e-01, -5.5327e-02,  ...,  2.1516e-01,\n",
      "            1.1641e-01,  1.3612e-01],\n",
      "          [-2.5434e-02,  4.9870e-01,  3.4327e-02,  ...,  3.1190e-01,\n",
      "           -2.0514e-01, -2.5864e-04],\n",
      "          ...,\n",
      "          [ 1.0371e-01,  6.5344e-01, -1.6192e-01,  ...,  2.3268e-01,\n",
      "           -9.8990e-02,  4.7273e-02],\n",
      "          [ 1.3105e-01,  5.0976e-01,  2.9566e-02,  ...,  3.8688e-01,\n",
      "           -1.6917e-01,  3.1523e-02],\n",
      "          [ 1.8170e-02,  5.5904e-01,  8.7325e-04,  ...,  1.9942e-01,\n",
      "           -9.6126e-03,  1.4290e-02]],\n",
      "\n",
      "         [[ 1.0648e-01, -3.0143e-01,  5.3091e-01,  ..., -5.3603e-02,\n",
      "            5.9712e-01,  1.0188e-01],\n",
      "          [ 9.5485e-02, -3.7769e-01,  6.4304e-01,  ..., -1.5497e-01,\n",
      "            3.7597e-01,  2.9454e-01],\n",
      "          [ 1.0097e-01, -1.7937e-01,  5.6100e-01,  ...,  5.8368e-02,\n",
      "            5.7162e-01,  1.7131e-01],\n",
      "          ...,\n",
      "          [ 2.4274e-01, -2.9807e-01,  5.2358e-01,  ...,  3.9713e-02,\n",
      "            5.1092e-01,  1.6314e-01],\n",
      "          [ 1.2376e-01, -1.9680e-01,  6.5872e-01,  ...,  2.3425e-01,\n",
      "            6.7627e-01,  1.7025e-01],\n",
      "          [ 6.9250e-02, -2.6753e-01,  4.7882e-01,  ..., -1.0979e-01,\n",
      "            8.4480e-01,  1.6573e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0124e-01,  4.3236e-01,  3.9207e-01,  ..., -5.9203e-02,\n",
      "            2.9667e-01, -4.4117e-02],\n",
      "          [ 1.5594e-01,  1.3509e-01,  1.8930e-01,  ..., -2.1228e-01,\n",
      "            1.7087e-01, -2.6073e-01],\n",
      "          [ 9.6447e-02,  2.0005e-01,  3.4514e-01,  ..., -2.7508e-01,\n",
      "            1.3682e-01, -4.0309e-01],\n",
      "          ...,\n",
      "          [ 4.7501e-04,  1.0162e-01,  1.9242e-01,  ..., -2.7333e-01,\n",
      "            7.4543e-02, -9.2175e-02],\n",
      "          [ 1.2477e-01,  1.4123e-01,  2.3740e-01,  ..., -2.1144e-01,\n",
      "            2.6045e-01,  4.6454e-03],\n",
      "          [ 6.2703e-02,  1.6708e-01,  4.6606e-01,  ..., -1.4129e-01,\n",
      "            2.9204e-01, -1.3068e-01]],\n",
      "\n",
      "         [[ 2.2237e-01, -1.9253e-01, -1.8346e-01,  ..., -6.6175e-02,\n",
      "           -2.9569e-01, -1.9647e-01],\n",
      "          [ 1.6340e-01, -3.6711e-01, -1.3793e-01,  ..., -1.4210e-01,\n",
      "           -1.9216e-01, -5.7851e-02],\n",
      "          [ 1.6240e-01, -1.0765e-01, -1.9455e-01,  ..., -1.2478e-01,\n",
      "           -3.9188e-01, -1.2723e-01],\n",
      "          ...,\n",
      "          [ 1.1478e-01, -2.4501e-01, -1.6157e-01,  ...,  1.6632e-01,\n",
      "           -1.3937e-01, -3.7937e-02],\n",
      "          [ 1.4898e-01, -1.2439e-01,  1.8561e-02,  ...,  2.5532e-02,\n",
      "           -2.5132e-01, -1.3610e-01],\n",
      "          [-2.0245e-02, -1.3214e-01, -1.6121e-01,  ...,  4.0436e-03,\n",
      "           -1.8318e-01, -2.1277e-02]],\n",
      "\n",
      "         [[-2.2870e-01,  3.4512e-01,  2.7441e-01,  ...,  5.9929e-01,\n",
      "           -1.0175e+00, -8.1004e-02],\n",
      "          [-1.1143e-01,  4.3965e-01,  2.2950e-01,  ...,  6.3780e-01,\n",
      "           -7.6867e-01, -4.4139e-03],\n",
      "          [-3.6502e-01,  6.0836e-01,  2.7002e-01,  ...,  7.5914e-01,\n",
      "           -7.8751e-01, -9.0568e-02],\n",
      "          ...,\n",
      "          [-2.5946e-01,  4.7813e-01,  2.3001e-01,  ...,  1.0531e+00,\n",
      "           -7.7959e-01, -1.5308e-01],\n",
      "          [-3.7642e-01,  4.3101e-01,  1.7709e-01,  ...,  6.4822e-01,\n",
      "           -7.5716e-01, -1.5965e-02],\n",
      "          [-1.3864e-01,  3.9370e-01,  2.4943e-01,  ...,  6.1319e-01,\n",
      "           -8.7521e-01, -4.8229e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8665e-01, -9.2835e-03, -5.3721e-02,  ...,  1.6321e-01,\n",
      "            3.5279e-01,  1.1011e+00],\n",
      "          [-1.7812e-01,  2.1622e-01,  6.6683e-02,  ..., -1.1421e-01,\n",
      "            3.9541e-01,  9.5442e-01],\n",
      "          [-7.4587e-02,  1.5547e-01, -2.3875e-02,  ..., -2.5716e-01,\n",
      "            3.0871e-01,  1.0427e+00],\n",
      "          ...,\n",
      "          [-1.3012e-01,  8.9037e-02,  1.5761e-02,  ..., -2.2131e-01,\n",
      "            2.9100e-01,  8.3837e-01],\n",
      "          [-3.4984e-01,  1.1914e-01, -3.8343e-02,  ..., -2.1579e-01,\n",
      "            4.0022e-01,  8.5315e-01],\n",
      "          [-2.2229e-01,  1.2339e-01,  2.0338e-02,  ..., -2.0558e-01,\n",
      "            4.0467e-01,  9.5485e-01]],\n",
      "\n",
      "         [[ 1.0883e-01,  6.6549e-01, -1.5908e-01,  ..., -8.4443e-02,\n",
      "           -5.4607e-02, -1.1000e-01],\n",
      "          [ 9.1426e-02,  7.0482e-01, -2.0584e-01,  ...,  3.6453e-01,\n",
      "           -2.3130e-01, -9.2112e-03],\n",
      "          [ 9.7150e-02,  5.1517e-01, -3.7925e-01,  ...,  2.5811e-01,\n",
      "            4.0472e-03, -3.8679e-02],\n",
      "          ...,\n",
      "          [ 1.4060e-01,  4.6687e-01, -7.5485e-02,  ...,  3.6222e-01,\n",
      "           -1.7814e-01, -1.7825e-01],\n",
      "          [ 3.2898e-02,  6.3477e-01, -2.0420e-01,  ...,  4.2798e-01,\n",
      "           -1.8824e-01, -1.4792e-02],\n",
      "          [ 5.0748e-02,  5.3198e-01, -2.7483e-01,  ...,  2.0537e-01,\n",
      "           -1.6809e-01, -2.2505e-01]],\n",
      "\n",
      "         [[ 1.6238e-01, -4.5928e-01,  5.6269e-01,  ...,  4.3106e-02,\n",
      "            6.5939e-01,  3.8714e-01],\n",
      "          [ 1.2711e-01, -4.2849e-01,  4.7232e-01,  ...,  1.0544e-01,\n",
      "            6.4339e-01,  3.6278e-01],\n",
      "          [ 1.6326e-01, -5.2711e-01,  5.5774e-01,  ..., -1.0518e-01,\n",
      "            5.8298e-01,  4.3497e-01],\n",
      "          ...,\n",
      "          [ 1.1613e-01, -4.2943e-01,  4.2580e-01,  ..., -5.9527e-02,\n",
      "            5.3575e-01,  2.3005e-01],\n",
      "          [ 1.3227e-01, -4.4590e-01,  4.4766e-01,  ..., -1.2302e-01,\n",
      "            7.3598e-01,  1.0523e-01],\n",
      "          [ 2.0277e-01, -4.4553e-01,  5.9826e-01,  ..., -5.6400e-02,\n",
      "            5.2954e-01,  3.7955e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1365e-02,  3.3780e-01,  3.0381e-01,  ..., -2.1719e-01,\n",
      "            3.3044e-01, -3.1132e-01],\n",
      "          [ 6.0518e-02,  3.9327e-01,  4.3626e-01,  ..., -1.4749e-01,\n",
      "            1.8560e-01, -1.8395e-01],\n",
      "          [ 1.0753e-01,  5.6440e-03,  3.6131e-01,  ..., -3.6153e-01,\n",
      "            3.1084e-01, -3.5557e-01],\n",
      "          ...,\n",
      "          [ 1.8217e-01,  3.7872e-01,  3.2778e-01,  ..., -5.6850e-02,\n",
      "            1.9711e-01, -3.1388e-01],\n",
      "          [ 1.3199e-01,  2.1693e-01,  3.6911e-01,  ..., -2.7941e-01,\n",
      "            2.2680e-01, -2.4250e-01],\n",
      "          [ 1.6552e-01,  3.8230e-01,  3.1364e-01,  ..., -7.6485e-02,\n",
      "            2.6616e-01, -7.5658e-02]],\n",
      "\n",
      "         [[ 1.2157e-01, -2.4330e-01, -3.3000e-01,  ...,  5.2765e-03,\n",
      "           -4.1570e-01, -7.2757e-02],\n",
      "          [ 3.2754e-01,  7.7021e-02, -4.0118e-01,  ..., -3.7986e-01,\n",
      "           -4.2221e-01, -1.1885e-02],\n",
      "          [ 1.0129e-01, -2.7585e-01, -3.8910e-01,  ..., -1.1909e-01,\n",
      "           -1.6910e-01,  3.6481e-02],\n",
      "          ...,\n",
      "          [ 9.4280e-02, -2.6629e-01, -4.0937e-01,  ..., -1.4941e-01,\n",
      "           -2.4306e-01,  1.0018e-01],\n",
      "          [-1.8994e-02, -2.0503e-01, -3.5102e-01,  ..., -1.8130e-01,\n",
      "           -4.0314e-01, -1.0350e-01],\n",
      "          [ 1.6460e-01, -1.2122e-01, -3.0583e-01,  ..., -1.6739e-01,\n",
      "           -4.0320e-01,  1.7558e-01]],\n",
      "\n",
      "         [[-4.7917e-01,  2.7280e-01,  6.4929e-02,  ...,  5.5630e-01,\n",
      "           -6.7157e-01,  1.2381e-01],\n",
      "          [-3.0710e-01,  2.8849e-01,  8.8600e-02,  ...,  5.7495e-01,\n",
      "           -6.1001e-01,  4.5379e-02],\n",
      "          [-2.7658e-01,  1.0072e-01,  3.2916e-01,  ...,  5.2787e-01,\n",
      "           -7.2234e-01, -7.6732e-02],\n",
      "          ...,\n",
      "          [-3.4919e-01,  2.1196e-01,  6.4047e-02,  ...,  5.1366e-01,\n",
      "           -6.1774e-01,  2.5348e-01],\n",
      "          [-3.8133e-01,  3.1744e-01,  4.9571e-03,  ...,  5.9629e-01,\n",
      "           -6.5974e-01, -6.6360e-02],\n",
      "          [-3.9110e-01,  2.5853e-01,  1.6607e-01,  ...,  4.6376e-01,\n",
      "           -5.8153e-01,  5.2752e-02]]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = torch.matmul(attention, V)  # (batch_size, num_heads, seq_len, head_dim)\n",
    "print(\"加权求和后的输出 output 的形状：\", output.shape)\n",
    "print(\"加权求和后的输出 output 的值：\\n\", output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 2.1.5 拼接多头 🐱 将多个注意力头的输出拼接回原始维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1. 拼接多头的作用**\n",
    "- **恢复原始维度**：\n",
    "  - 在分割多头时，我们将`d_model`拆分为`num_heads * head_dim`。\n",
    "  - 拼接多头的作用是将多个注意力头的输出拼接回`d_model`维度。\n",
    "- **生成最终输出**：\n",
    "  - 拼接后的输出形状为`(batch_size, seq_len, d_model)`，可以直接用于后续的计算。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output 的形状： torch.Size([32, 16, 50, 32])\n"
     ]
    }
   ],
   "source": [
    "# output 是加权求和的结果，形状为 (batch_size, num_heads, seq_len, head_dim)\n",
    "batch_size, num_heads, seq_len, head_dim = output.shape\n",
    "print(\"output 的形状：\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转置后的 output 的形状： torch.Size([32, 50, 16, 32])\n",
      "拼接后的 output 的形状： torch.Size([32, 50, 512])\n"
     ]
    }
   ],
   "source": [
    "# 1. 转置：将 num_heads 维度移到后面\n",
    "output = output.transpose(1, 2)  # (batch_size, seq_len, num_heads, head_dim)\n",
    "print(\"转置后的 output 的形状：\", output.shape)\n",
    "\n",
    "# 2. 拼接：将 num_heads 和 head_dim 合并为 d_model\n",
    "output = output.reshape(batch_size, seq_len, -1)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "print(\"拼接后的 output 的形状：\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 2.1.6 线性变换 🐱 将拼接后的输出映射回原始维度\n",
    "\n",
    "这部分用于将之前获得的拼接结果用线性变换层映射到另外一个特征空间。这也可以用于适应下一部分``Feed-Forward Network``的输入维度。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "线性变换后的 output 的形状： torch.Size([32, 50, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 定义线性变换层\n",
    "# 我们原来设置的d_model是512\n",
    "d_model = 512\n",
    "output_projection = nn.Linear(d_model, d_model)\n",
    "\n",
    "# 线性变换\n",
    "projected_output = output_projection(output)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "print(\"线性变换后的 output 的形状：\", projected_output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2 Feed-Forward Network 🐱 前馈神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **特征转换**：\n",
    "  - 将多头注意力机制的输出进一步映射到更高维的特征空间。\n",
    "  - 通过非线性激活函数（如ReLU）引入非线性变换。\n",
    "- **独立处理**：\n",
    "  - 对序列中的每个位置独立处理，不依赖其他位置的信息。\n",
    "- **增强表达能力**：\n",
    "  - 通过多层全连接网络增强模型的表达能力。\n",
    "\n",
    "前馈神经网络通常由两层全连接层组成：\n",
    "1. **第一层**：\n",
    "   - 输入维度：`d_model`\n",
    "   - 输出维度：`d_ff`（通常为`4 * d_model`）\n",
    "   - 激活函数：ReLU\n",
    "2. **第二层**：\n",
    "   - 输入维度：`d_ff`\n",
    "   - 输出维度：`d_model`\n",
    "   - 无激活函数\n",
    "\n",
    "当然了你可以随意设置层数和神经元数量，在此我只是示范而已。\n",
    "\n",
    "很像autoencoder的结构不是吗🐱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)  # 第一层全连接\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)  # 第二层全连接\n",
    "        self.activation = nn.ReLU()  # 激活函数\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, d_model)\n",
    "        x = self.linear1(x)  # (batch_size, seq_len, d_ff)\n",
    "        x = self.activation(x)  # 非线性变换\n",
    "        x = self.linear2(x)  # (batch_size, seq_len, d_model)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projected_output 的形状： torch.Size([32, 50, 512])\n",
      "ffn_output 的形状： torch.Size([32, 50, 512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d_ff = 2048  # 通常为 4 * d_model\n",
    "\n",
    "# 我们已经获得了projected_output，形状为 (batch_size, seq_len, d_model)\n",
    "print(\"projected_output 的形状：\", projected_output.shape)\n",
    "# 前馈神经网络\n",
    "ffn = FeedForwardNetwork(d_model, d_ff)\n",
    "ffn_output = ffn(projected_output)\n",
    "\n",
    "print(\"ffn_output 的形状：\", ffn_output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.3 Residual Connection & Layer Normalization 🐱 残差连接和层归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 2.3.1 为什么要进行残差连接？\n",
    "也许你已经注意到，前馈神经网络的输出`ffn_output 的形状： torch.Size([32, 50, 512])`与预处理之后的数据`x = preprocessor(input_ids)`、多头注意力的输出`拼接后的 output 的形状： torch.Size([32, 50, 512])`的形状一致。这让我们想到也许能够将其进行相加之类的操作。\n",
    "\n",
    "**（1）保留原始信息**\n",
    "- 多头注意力机制已经捕捉了序列中元素之间的关系。\n",
    "- 残差连接确保这些信息不会被前馈神经网络完全覆盖，保留原始特征。\n",
    "\n",
    "**（2）缓解梯度消失**\n",
    "- 深层网络中，梯度在反向传播时容易消失。\n",
    "- 残差连接提供了一条“捷径”，使梯度可以直接传播到浅层，缓解梯度消失问题。\n",
    "\n",
    "**（3）增强模型表达能力**\n",
    "- 前馈神经网络引入了非线性变换，增强了模型的表达能力。\n",
    "- 残差连接将这种非线性变换与原始特征结合，进一步提升模型性能。\n",
    "\n",
    "**（4）加速训练**\n",
    "- 残差连接使模型更容易优化，加速训练过程。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "残差连接和层归一化后的 x 的形状： torch.Size([32, 50, 512])\n"
     ]
    }
   ],
   "source": [
    "norm1 = nn.LayerNorm(d_model)\n",
    "\n",
    "x = norm1(x + projected_output)\n",
    "\n",
    "print(\"残差连接和层归一化后的 x 的形状：\", x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "在此之后，这个`x`再经过我们之前提到过的`Feed-Forward`得到的`ffn_output = ffn(projected_output)`进行残差链接，最后将`x`进行层归一化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "残差连接和层归一化后的 x 的形状： torch.Size([32, 50, 512])\n"
     ]
    }
   ],
   "source": [
    "norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "x = norm2(x + ffn_output)\n",
    "\n",
    "print(\"残差连接和层归一化后的 x 的形状：\", x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2.3.2 为什么要层归一化？\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "层归一化（Layer Normalization）是一种用于神经网络中的归一化技术，主要用于加速训练过程并提高模型的稳定性。以下是详细解释：\n",
    "\n",
    "**. 层归一化的作用**\n",
    "- **归一化特征**：\n",
    "  - 对每个样本的特征进行归一化，使其均值为0，方差为1。\n",
    "  - 减少内部协变量偏移（Internal Covariate Shift），使训练更稳定。\n",
    "- **加速收敛**：\n",
    "  - 归一化后的特征分布更稳定，有助于加速模型收敛。\n",
    "- **适用于不同任务**：\n",
    "  - 特别适合处理变长序列（如NLP任务）和小批量数据。\n",
    "\n",
    "**. 层归一化的公式**\n",
    "层归一化的计算公式如下：\n",
    "```python\n",
    "y = (x - mean) / sqrt(var + eps) * gamma + beta\n",
    "```\n",
    "- **`x`**：输入特征。\n",
    "- **`mean`**：输入特征的均值。\n",
    "- **`var`**：输入特征的方差。\n",
    "- **`eps`**：一个小常数，用于数值稳定性（默认`1e-5`）。\n",
    "- **`gamma`**：可学习的缩放参数（权重）。\n",
    "- **`beta`**：可学习的偏移参数（偏置）。\n",
    "\n",
    "---\n",
    "\n",
    "**. 层归一化的特点**\n",
    "- **独立于批量大小**：\n",
    "  - 与批量归一化（Batch Normalization）不同，层归一化不依赖于批量大小，适合处理小批量或变长序列。\n",
    "- **逐样本归一化**：\n",
    "  - 对每个样本的特征进行归一化，而不是跨样本归一化。\n",
    "- **可学习的参数**：\n",
    "  - `gamma` 和 `beta` 是可学习的参数，允许模型调整归一化后的特征分布。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上就是`Encoder`中一个`EncoderLayer`的全部内容，为了获取`Encoder`，我们需要将`EncoderLayer`堆叠起来。你可以在`transformer_encoder.py`中找到完整的代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Decoder 🐱 解码器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1. **掩码多头自注意力**：\n",
    "   - 捕捉已生成序列的内部关系。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3.1.1 为什么就需要掩码了？之前的Encoder中的注意力不需要掩码呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### 1. **任务性质不同**\n",
    "- **Encoder**：\n",
    "  - 处理的是完整的输入序列（如源语言句子）\n",
    "  - 需要同时看到整个序列的所有信息\n",
    "  - 目标是捕捉序列中所有元素之间的关系\n",
    "\n",
    "- **Decoder**：\n",
    "  - 处理的是目标序列（如目标语言句子）\n",
    "  - 需要逐步生成序列，不能\"偷看\"未来信息\n",
    "  - 目标是基于已生成的部分序列和Encoder的输出来预测下一个元素\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### 2. **掩码的作用**\n",
    "- **防止信息泄露**：\n",
    "  - 在训练时，Decoder会接收完整的目标序列\n",
    "  - 如果没有掩码，模型可能会直接\"看到\"未来的信息，导致训练作弊\n",
    "  - 掩码确保模型只能使用当前位置及之前的信息\n",
    "\n",
    "- **保持自回归性质**：\n",
    "  - 在推理时，Decoder需要逐个生成序列元素\n",
    "  - 掩码确保模型只能基于已生成的部分序列进行预测\n",
    "  - 这是序列生成任务（如机器翻译、文本生成）的基本要求\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "##### 3. **具体实现**\n",
    "- **Encoder中的注意力**：\n",
    "  - 计算注意力分数时，所有位置之间都可以相互关注\n",
    "  - 不需要任何限制，因为整个输入序列是已知的\n",
    "\n",
    "- **Decoder中的掩码注意力**：\n",
    "  - 使用下三角掩码（`torch.tril`）\n",
    "  - 确保每个位置只能关注到它自身及之前的位置\n",
    "  - 未来位置的注意力分数被设置为`-inf`，在softmax后权重为0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 的形状： torch.Size([32, 16, 50, 32])\n",
      "K 的形状： torch.Size([32, 16, 50, 32])\n",
      "Encoder注意力分数 scores 的形状： torch.Size([32, 16, 50, 50])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask 的形状： torch.Size([50, 50])\n",
      "mask 的值： tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "Decoder注意力分数 scores 的形状： torch.Size([32, 16, 50, 50])\n",
      "mask 的形状： torch.Size([50, 50])\n",
      "mask 的值： tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "\n",
    "Q = torch.randn(32, 16, 50 ,32)\n",
    "K = torch.randn(32, 16, 50 ,32)\n",
    "\n",
    "print(\"Q 的形状：\", Q.shape)\n",
    "print(\"K 的形状：\", K.shape)\n",
    "\n",
    "# Encoder注意力分数（无掩码）\n",
    "scores = torch.matmul(Q, K.transpose(-2, -1)) / sqrt(head_dim)\n",
    "# print(\"Encoder注意力分数 scores：\", scores)\n",
    "print(\"Encoder注意力分数 scores 的形状：\", scores.shape)\n",
    "\n",
    "\n",
    "# Decoder注意力分数（带掩码）\n",
    "scores = torch.matmul(Q, K.transpose(-2, -1)) / sqrt(head_dim)\n",
    "# 生成下三角掩码\n",
    "seq_len = 50  # 序列长度为50\n",
    "mask = torch.tril(torch.ones(seq_len, seq_len))  # 下三角掩码\n",
    "\n",
    "# 可视化掩码\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(mask, cmap='gray', vmin=0, vmax=1)\n",
    "plt.title(\"Lower Triangular Mask\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# 打印掩码的形状和值\n",
    "print(\"mask 的形状：\", mask.shape)\n",
    "print(\"mask 的值：\", mask)\n",
    "scores = scores.masked_fill(mask == 0, float('-inf'))  # 应用掩码\n",
    "# print(\"Decoder注意力分数 scores：\", scores)\n",
    "print(\"Decoder注意力分数 scores 的形状：\", scores.shape)\n",
    "print(\"mask 的形状：\", mask.shape)\n",
    "print(\"mask 的值：\", mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### 3.1.2 为什么需要下三角掩码？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### 1. **自回归任务的性质**\n",
    "在自回归任务中，模型需要**逐步生成序列**，即每次只能基于已经生成的部分序列来预测下一个元素。例如：\n",
    "- 在文本生成中，模型只能基于已经生成的单词来预测下一个单词。\n",
    "- 在机器翻译中，模型只能基于已经生成的目标语言单词来预测下一个单词。\n",
    "\n",
    "如果模型能够“看到”未来的信息，它就会作弊，直接使用未来的信息来预测当前的位置，这会导致训练和推理不一致。\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. **下三角掩码的作用**\n",
    "下三角掩码的作用是**限制模型只能访问当前位置及之前的信息**，而不能访问未来的信息。具体来说：\n",
    "- **下三角部分**：值为1，表示允许模型访问这些位置的信息。\n",
    "- **上三角部分**：值为0，表示禁止模型访问这些位置的信息。\n",
    "\n",
    "通过将上三角部分的注意力分数设置为`-inf`，在softmax操作后，这些位置的权重会变为0，从而确保模型无法利用未来的信息。\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. **掩码的实现**\n",
    "在代码中，下三角掩码通常通过`torch.tril`函数生成：\n",
    "````python\n",
    "mask = torch.tril(torch.ones(seq_len, seq_len))\n",
    "````\n",
    "例如，对于一个长度为5的序列，掩码矩阵如下：\n",
    "````\n",
    "1 0 0 0 0\n",
    "1 1 0 0 0\n",
    "1 1 1 0 0\n",
    "1 1 1 1 0\n",
    "1 1 1 1 1\n",
    "````\n",
    "- 第1行：只能看到第1个位置。\n",
    "- 第2行：可以看到第1和第2个位置。\n",
    "- 第3行：可以看到第1、第2和第3个位置。\n",
    "- 以此类推。\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. **为什么需要下三角掩码？**\n",
    "###### （1）**训练时防止信息泄露**\n",
    "- 在训练时，Decoder会接收完整的目标序列（如目标语言句子）。\n",
    "- 如果没有掩码，模型可能会直接“看到”未来的信息，导致训练作弊。\n",
    "- 掩码确保模型只能使用当前位置及之前的信息。\n",
    "\n",
    "###### （2）**推理时保持自回归性质**\n",
    "- 在推理时，Decoder需要逐个生成序列元素。\n",
    "- 掩码确保模型只能基于已生成的部分序列进行预测。\n",
    "- 这是序列生成任务（如机器翻译、文本生成）的基本要求。\n",
    "\n",
    "###### （3）**确保训练和推理一致性**\n",
    "- 训练时使用掩码，推理时也使用掩码，确保模型的行为一致。\n",
    "- 如果训练时不使用掩码，模型可能会学习到依赖未来信息的错误模式，导致推理时性能下降。\n",
    "\n",
    "---\n",
    "\n",
    "##### 5. **示例**\n",
    "假设我们有一个长度为3的序列，计算注意力分数时：\n",
    "- **无掩码**：模型可以看到所有位置的信息。\n",
    "  ````\n",
    "  scores = [[s11, s12, s13],\n",
    "            [s21, s22, s23],\n",
    "            [s31, s32, s33]]\n",
    "  ````\n",
    "- **有掩码**：模型只能看到当前位置及之前的信息。\n",
    "  ````\n",
    "  scores = [[s11, -inf, -inf],\n",
    "            [s21, s22, -inf],\n",
    "            [s31, s32, s33]]\n",
    "  ````\n",
    "在softmax后，`-inf`的位置权重为0，模型无法利用这些信息。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### 6. **总结**\n",
    "| 特性                | 无掩码                  | 下三角掩码              |\n",
    "|---------------------|------------------------|------------------------|\n",
    "| 信息访问            | 可以访问整个序列        | 只能访问当前位置及之前  |\n",
    "| 训练时              | 可能作弊，利用未来信息  | 防止信息泄露            |\n",
    "| 推理时              | 无法逐步生成序列        | 保持自回归性质          |\n",
    "| 适用场景            | Encoder                | Decoder                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 输入是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. tgt: 目标序列的嵌入表示。也就是我们之前通过TransformerPreprocessor得到的被预处理的输入。\n",
    "2. tgt_mask: 下三角掩码，用于限制模型只能访问当前位置及之前的信息。\n",
    "3. memory: Encoder的输出，用于计算Encoder-Decoder Attention。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Output Layer 🐱 输出层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在《Attention is All You Need》论文中，输出层的主要意义是将解码器的输出转换为最终的预测结果。具体来说，输出层的作用包括：\n",
    "\n",
    "1. **线性变换**：将解码器的输出（通常是高维向量，在我们的例子中`输出: torch.Size([32, 50, 512])`）映射到词汇表大小的维度。这一步通过一个线性层（`nn.Linear`）实现，生成每个位置每个词的概率分数（logits）。\n",
    "\n",
    "2. **生成概率分布**：通过 Softmax 函数将 logits 转换为概率分布。这个概率分布表示每个位置每个词的概率，模型可以根据这个分布选择最可能的词作为输出。\n",
    "\n",
    "3. **序列生成**：在序列生成任务（如机器翻译、文本生成等）中，输出层的概率分布用于生成最终的序列。通常，模型会选择概率最高的词作为下一个词，逐步生成整个序列。\n",
    "\n",
    "总结来说，输出层的作用是将解码器的抽象表示转换为具体的词汇概率分布，从而生成最终的预测结果。这是 Transformer 模型完成序列生成任务的关键步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits 形状: torch.Size([32, 50, 10000])\n",
      "概率分布形状: torch.Size([32, 50, 10000])\n"
     ]
    }
   ],
   "source": [
    "class OutputLayer(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super(OutputLayer, self).__init__()\n",
    "        # 线性层，将 d_model 维映射到词汇表大小\n",
    "        self.linear = nn.Linear(d_model, vocab_size) # 别忘了我们设置d_model为512，vocab_size为10000\n",
    "        # Softmax 函数，用于生成概率分布\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 线性变换，输出形状: [batch_size, seq_len, vocab_size]\n",
    "        logits = self.linear(x)\n",
    "        # Softmax 生成概率分布\n",
    "        probs = self.softmax(logits)\n",
    "        return logits, probs\n",
    "    \n",
    "\n",
    "# 初始化输出层\n",
    "output_layer = OutputLayer(d_model=512, vocab_size=vocab_size)\n",
    "\n",
    "# 解码器的输出，形状为 [32, 50, 512]\n",
    "decoder_output = torch.randn(32, 50, 512)\n",
    "\n",
    "# 前向传播\n",
    "logits, probs = output_layer(decoder_output)\n",
    "\n",
    "# 检查输出形状\n",
    "print(\"Logits 形状:\", logits.shape)  # 输出: torch.Size([32, 50, 10000])\n",
    "print(\"概率分布形状:\", probs.shape)  # 输出: torch.Size([32, 50, 10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **`logits` 形状 `[32, 50, 10000]`**：\n",
    "  - `32` 是批次大小（batch size），表示同时处理 32 个样本。\n",
    "  - `50` 是序列长度（sequence length），表示每个样本有 50 个时间步或位置。\n",
    "  - `10000` 是词汇表大小（vocab size），表示每个位置有 10000 个可能的词。\n",
    "\n",
    "- **`probs` 形状 `[32, 50, 10000]`**：\n",
    "  - 这是 `logits` 经过 Softmax 后的概率分布，形状与 `logits` 相同。\n",
    "  - 每个位置的概率分布总和为 1，表示模型对每个位置预测的词的概率。\n",
    "\n",
    "### 为什么是这种形状？\n",
    "- 这种形状符合 Transformer 的输出设计，适用于序列生成任务（如机器翻译、文本生成等）。\n",
    "- 每个位置的概率分布可以用于选择最可能的词，逐步生成输出序列。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
