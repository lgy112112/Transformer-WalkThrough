{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下载完成并保存为 shakespeare.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "if os.path.exists('shakespeare.txt'):\n",
    "    pass\n",
    "else:\n",
    "    # 下载并保存文件\n",
    "    url = 'https://www.gutenberg.org/files/100/100-0.txt'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # 移除UTF-8 BOM\n",
    "    text = response.content.decode('utf-8-sig') # 可以注释掉这行代码，你会发现获得的文本含有一些乱码\n",
    "\n",
    "    with open('shakespeare.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "    print(\"下载完成并保存为 shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1686447 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "源文本:  their examination yourself, and bring it me: I am now in\n",
      "great haste, as may appear unto you.\n",
      "\n",
      "DOGBERRY.\n",
      "It shall be suffigance.\n",
      "\n",
      "LEONATO.\n",
      "Drink some wine ere you go: fare you well.\n",
      "\n",
      "Enter a Messenger.\n",
      "\n",
      "MESSENGER.\n",
      "My lord, they stay for you to give your daughter to her husband.\n",
      "\n",
      "LEONATO.\n",
      "I’ll wait upon them: I am ready.\n",
      "\n",
      "[Exeunt Leonato and Messenger.]\n",
      "\n",
      "DOGBERRY.\n",
      "Go\n",
      "目标文本:  examination yourself, and bring it me: I am now in\n",
      "great haste, as may appear unto you.\n",
      "\n",
      "DOGBERRY.\n",
      "It shall be suffigance.\n",
      "\n",
      "LEONATO.\n",
      "Drink some wine ere you go: fare you well.\n",
      "\n",
      "Enter a Messenger.\n",
      "\n",
      "MESSENGER.\n",
      "My lord, they stay for you to give your daughter to her husband.\n",
      "\n",
      "LEONATO.\n",
      "I’ll wait upon them: I am ready.\n",
      "\n",
      "[Exeunt Leonato and Messenger.]\n",
      "\n",
      "DOGBERRY.\n",
      "Go,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformer import Transformer\n",
    "import random\n",
    "\n",
    "# 1. 加载数据\n",
    "with open('shakespeare.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# 2. 使用GPT2的分词器（或其他分词器）\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "# 3. 创建数据集\n",
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, tokens, seq_length):\n",
    "        self.tokens = tokens\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens) // self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.seq_length\n",
    "        end = start + self.seq_length + 1  # 多取一个 token 用于目标序列\n",
    "        seq = self.tokens[start:end]\n",
    "        \n",
    "        src = seq[:-1]  # 源文本：去掉最后一个 token\n",
    "        tgt = seq[1:]   # 目标文本：去掉第一个 token\n",
    "        \n",
    "        return torch.tensor(src, dtype=torch.long), torch.tensor(tgt, dtype=torch.long)\n",
    "\n",
    "\n",
    "seq_length = 128\n",
    "dataset = ShakespeareDataset(tokens, seq_length)\n",
    "# 随机选择一个样本\n",
    "random_index = random.randint(0, len(dataset) - 1)\n",
    "src, tgt = dataset[random_index]\n",
    "\n",
    "# 将 token 转换回文本\n",
    "src_text = tokenizer.decode(src.tolist())\n",
    "tgt_text = tokenizer.decode(tgt.tolist())\n",
    "\n",
    "# 显示结果\n",
    "print(f\"源文本: {src_text}\")\n",
    "print(f\"目标文本: {tgt_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. 创建数据加载器\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=8)\n",
    "\n",
    "# 5. 定义模型、损失函数和优化器\n",
    "model = Transformer(vocab_size=tokenizer.vocab_size, d_model=512, num_heads=8, num_layers=2, d_ff=2048, max_seq_len=seq_length)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|▋         | 120/1647 [01:39<20:54,  1.22batch/s, Batch Loss=2.12]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 6. 训练循环\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0  # 用于累积每个 epoch 的 loss\n",
    "    with tqdm(dataloader, desc=f\"Epoch {epoch+1}\", unit=\"batch\") as pbar:\n",
    "        for batch in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch[:, :-1], batch[:, 1:])\n",
    "            loss = criterion(output.view(-1, tokenizer.vocab_size), batch[:, 1:].reshape(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 更新 epoch_loss\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # 实时显示当前 batch 的 loss\n",
    "            pbar.set_postfix({\"Batch Loss\": loss.item()})\n",
    "\n",
    "    # 计算并打印每个 epoch 的平均 loss\n",
    "    avg_epoch_loss = epoch_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/10], Avg Loss: {avg_epoch_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
