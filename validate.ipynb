{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os \n",
    "\n",
    "if os.path.exists('shakespeare.txt'):\n",
    "    pass\n",
    "else:\n",
    "    # 下载并保存文件\n",
    "    url = 'https://www.gutenberg.org/files/100/100-0.txt'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # 移除UTF-8 BOM\n",
    "    text = response.content.decode('utf-8-sig') # 可以注释掉这行代码，你会发现获得的文本含有一些乱码\n",
    "\n",
    "    with open('shakespeare.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "    print(\"下载完成并保存为 shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1686447 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformer import Transformer\n",
    "\n",
    "# 1. 加载数据\n",
    "with open('shakespeare.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# 2. 使用GPT2的分词器（或其他分词器）\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "# 3. 创建数据集\n",
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, tokens, seq_length):\n",
    "        self.tokens = tokens\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens) // self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.seq_length\n",
    "        end = start + self.seq_length\n",
    "        return torch.tensor(self.tokens[start:end], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# 4. 创建数据集\n",
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, tokens, seq_length):\n",
    "        self.tokens = tokens\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens) // self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.seq_length\n",
    "        end = start + self.seq_length\n",
    "        return torch.tensor(self.tokens[start:end], dtype=torch.long)\n",
    "\n",
    "# 5. 划分训练集和验证集\n",
    "seq_length = 128\n",
    "dataset = ShakespeareDataset(tokens, seq_length)\n",
    "train_size = int(0.8 * len(dataset))  # 80% 训练集\n",
    "val_size = len(dataset) - train_size  # 20% 验证集\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (preprocessor): TransformerPreprocessor(\n",
       "    (embedding): Embedding(50257, 512)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x DecoderLayer(\n",
       "        (masked_self_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_decoder_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=512, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. 定义模型、损失函数和优化器\n",
    "model = Transformer(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    num_layers=2,\n",
    "    d_ff=2048,\n",
    "    max_seq_len=seq_length\n",
    ")\n",
    "\n",
    "# 加载模型权重\n",
    "model.load_state_dict(torch.load('/teamspace/studios/this_studio/artifacts/best_model_val_loss=0.0780.pth'))\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入文本:  makes a still-stand, running neither way.\n",
      "Fain would I go to meet the Archbishop,\n",
      "But many thousand reasons hold me back.\n",
      "I will resolve for Scotland. There am I,\n",
      "Till time and vantage crave my company.\n",
      "\n",
      " [_Exeunt._]\n",
      "\n",
      "SCENE IV. London. The Boar’s head Tavern in Eastcheap.\n",
      "\n",
      "Enter two Drawers.\n",
      "\n",
      "FIRST DRAWER.\n",
      "What the devil hast thou brought there—applejohns? Thou knowest Sir\n",
      "John cannot endure an applejohn.\n",
      "\n",
      "SECOND DRAWER\n",
      "目标文本:  a still-stand, running neither way.\n",
      "Fain would I go to meet the Archbishop,\n",
      "But many thousand reasons hold me back.\n",
      "I will resolve for Scotland. There am I,\n",
      "Till time and vantage crave my company.\n",
      "\n",
      " [_Exeunt._]\n",
      "\n",
      "SCENE IV. London. The Boar’s head Tavern in Eastcheap.\n",
      "\n",
      "Enter two Drawers.\n",
      "\n",
      "FIRST DRAWER.\n",
      "What the devil hast thou brought there—applejohns? Thou knowest Sir\n",
      "John cannot endure an applejohn.\n",
      "\n",
      "SECOND DRAWER.\n",
      "预测文本:  a still-stand, running neither way.\n",
      "Fain would I go to meet the Archbishop,\n",
      "But many thousand reasons hold me back.\n",
      "I will resolve for Scotland. There am I,\n",
      "Till time and vantage crave my company.\n",
      "\n",
      " [_Exeunt._]\n",
      "\n",
      "SCENE IV. London. The Boar’s head Tavern in Eastcheap.\n",
      "\n",
      "Enter two Drawers.\n",
      "\n",
      "FIRST DRAWER.\n",
      "What the devil hast thou brought there—applejohns? Thou knowest Sir\n",
      "John cannot endure an applejohn.\n",
      "\n",
      "SECOND DRAWER.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# 从验证数据集中随机选取一个样本\n",
    "random_index = random.randint(0, len(val_dataset) - 1)\n",
    "sample = val_dataset[random_index]\n",
    "\n",
    "# 将样本转换为模型输入格式\n",
    "src = sample[:-1].unsqueeze(0)  # 去掉最后一个 token 作为输入\n",
    "tgt = sample[1:].unsqueeze(0)   # 去掉第一个 token 作为目标\n",
    "\n",
    "# 生成掩码\n",
    "src_pad_idx = 0  # 假设填充索引为0\n",
    "tgt_pad_idx = 0  # 假设填充索引为0\n",
    "src_mask = model.make_src_mask(src, src_pad_idx)\n",
    "tgt_mask = model.make_trg_mask(tgt, tgt_pad_idx)\n",
    "\n",
    "# 进行预测\n",
    "with torch.no_grad():\n",
    "    output = model(src, tgt, src_mask, tgt_mask)\n",
    "    predicted_tokens = torch.argmax(output, dim=-1)\n",
    "\n",
    "# 将 token 转换回文本\n",
    "input_text = tokenizer.decode(src.squeeze().tolist())\n",
    "target_text = tokenizer.decode(tgt.squeeze().tolist())\n",
    "predicted_text = tokenizer.decode(predicted_tokens.squeeze().tolist())\n",
    "\n",
    "# 显示结果\n",
    "print(f\"输入文本: {input_text}\")\n",
    "print(f\"目标文本: {target_text}\")\n",
    "print(f\"预测文本: {predicted_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
